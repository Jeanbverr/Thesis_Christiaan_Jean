{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found path with os.path.abspath('..'):  G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy as sc\n",
    "# import matplotlib.pyplot as plt\n",
    "from glob import glob \n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# adds the lower lying directory to the import path to import the other modules\n",
    "Lpath = os.path.abspath('..')\n",
    "print(\"found path with os.path.abspath('..'): \", Lpath)\n",
    "sys.path.insert(0, Lpath)\n",
    "\n",
    "import tflearn\n",
    "from face_detect import cutFace\n",
    "from showNumpyInfo import showInfo\n",
    "\n",
    "import logging\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile\", filemode=\"a+\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "logging.info(\"hello\")\n",
    "\n",
    "def logprint(stre):\n",
    "\tprint(stre)\n",
    "\tlogging.info(stre)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataPath = 'G:/Documenten/personal/school/MaNaMA_AI/thesis/databases/wikipedia_list/cohn-Kanade/CK+'\n",
    "datasetPath = dataPath\n",
    "printData = 1\n",
    "cascPath = \"G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/DeXpression-master_chris/haarcascade.xml\"\n",
    "allData = False,\n",
    "neutral = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores the current working directory path to restore at the end and goes to the given database path\n",
    "curr_path = os.getcwd()\n",
    "os.chdir(datasetPath)\n",
    "#get a list of URLs to all the emotion file that can be found\n",
    "label_list = glob('./Emotion/*/*/*.txt')\n",
    "\n",
    "X_data = [] # list of input data = climax images of emotions\n",
    "Y_data = [] # list of output data = emotion expressed in image\n",
    "X_subID = [] # list with subject Id of each X_data element \n",
    "\n",
    "# each emotion clip has only a few relevant images that represent an emotion \n",
    "relevant_part = 0.33 # the \"precentage\" of the end of the clip that has relevant images for that emotion\n",
    "\n",
    "\n",
    "i = 0 #count of total amount of instance\n",
    "tot_img_count = 0 # Count of how many images there are loaded\n",
    "\n",
    "#count per emotion\n",
    "N = 0 # Neutral\n",
    "A = 0 # Anger\n",
    "C = 0 # Contempt\n",
    "D = 0 # Disgust\n",
    "F = 0 # Fear\n",
    "H = 0 # Happy\n",
    "Sa = 0# Saddness\n",
    "Su = 0# Surprise\n",
    "\n",
    "#subject counter\n",
    "sub = 0\n",
    "lastSub = 0\n",
    "subjectID = 0\n",
    "\n",
    "#count of dimensions\n",
    "dimMap = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loading data\n",
      "20subjects loaded\n",
      "Maximum memory usage: [277.5, 277.53515625, 277.53515625, 277.53515625, 277.53515625]\n",
      "20subjects loaded\n",
      "Maximum memory usage: [281.44921875, 281.44921875, 281.44921875, 281.44921875, 281.44921875]\n",
      "40subjects loaded\n",
      "Maximum memory usage: [462.27734375, 462.28125, 462.28125, 462.28125, 462.28125]\n",
      "40subjects loaded\n",
      "Maximum memory usage: [466.5859375, 466.58984375, 466.58984375, 466.58984375, 466.58984375]\n",
      "60subjects loaded\n",
      "Maximum memory usage: [618.6015625, 618.6015625, 618.60546875, 618.60546875, 618.60546875]\n",
      "60subjects loaded\n",
      "Maximum memory usage: [621.20703125, 621.20703125, 621.2109375, 621.2109375, 621.2109375]\n",
      "80subjects loaded\n",
      "Maximum memory usage: [740.5625, 740.5625, 740.5625, 740.5625, 740.5625]\n",
      "80subjects loaded\n",
      "Maximum memory usage: [744.95703125, 744.95703125, 744.95703125, 744.95703125, 744.95703125]\n",
      "80subjects loaded\n",
      "Maximum memory usage: [747.7578125, 747.76171875, 747.76171875, 747.76171875, 747.76171875]\n",
      "100subjects loaded\n",
      "Maximum memory usage: [920.765625, 920.765625, 920.765625, 920.765625, 920.765625]\n",
      "length Y_data 4\n",
      "image type <class 'int'>\n",
      "Maximum memory usage: [993.50390625, 993.51171875, 993.51171875, 993.51171875, 993.51171875]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # image\n",
    "# img = cv2.imread(str)\n",
    "\n",
    "print(\"begin loading data\")\n",
    "#iterate through the list of label files, open corresponding images\n",
    "for fn in label_list:\n",
    "\n",
    "    str = './cohn-kanade-images'+ fn[9:-29] + '*.png'\n",
    "\n",
    "    # print(fn[9:-29])\n",
    "    # print(str)\n",
    "\n",
    "    img_list = glob(str)\n",
    "\n",
    "\n",
    "    img = []\n",
    "    img_neutral =[]\n",
    "\n",
    "    relevant_amount = int(round(len(img_list)*relevant_part))\n",
    "\n",
    "    # stre = \"from \" + repr( len(img_list)) +  \"amount of images only \" + repr(relevant_amount) + \" is relevant\"\n",
    "    # logging.info(stre)\n",
    "    tot_img_count = tot_img_count + relevant_amount \n",
    "    # print(\"tot_img_count \", tot_img_count)\n",
    "\n",
    "\n",
    "    #the first 3 images are taken as being neutral\n",
    "    count = 0\n",
    "    for url in img_list[0:3]:\n",
    "        # print(url)\n",
    "        image = cv2.imread(url)\n",
    "        img_neutral.append(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        N = N + 1\n",
    "        # stre = \"neutral img = \" + repr(count)\n",
    "        # cv2.imshow(stre, image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        count = count +1\n",
    "\n",
    "    # relevant amount of  the last frames are taken as belonging to that emotion\n",
    "    count = 0\n",
    "    for url in img_list[(len(img_list)-relevant_amount) :len(img_list)]:\n",
    "        # print(url)\n",
    "        image = cv2.imread(url)\n",
    "        img.append(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        # stre = \"emotion img = \" + repr(count)\n",
    "        # cv2.imshow(stre, image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        count = count +1\n",
    "\n",
    "\n",
    "    #sizeStr = repr(img.shape[0]) + \"x\" + repr(img.shape[1]) #+ \"x\" + repr(img.shape[2])\n",
    "\n",
    "    # test accessing single elements\n",
    "    # if sizeStr in dimMap:\n",
    "    # \tdimMap[sizeStr] = dimMap[sizeStr] + 1 \n",
    "    # else:\n",
    "    # \tdimMap[sizeStr] = 1\n",
    "\n",
    "    # read emotion labels from the file\n",
    "    file = open(fn,'r')\n",
    "    fileTxt = file.read()\n",
    "    emotionNr = int(fileTxt[3:4])\n",
    "    file.close()\n",
    "\n",
    "    #determine the subject (number is within URL)\n",
    "    subjectID = fn[11:14]\n",
    "    if subjectID != lastSub :\n",
    "        sub = sub + 1\n",
    "    lastSub = subjectID \n",
    "\n",
    "    #determine the emotion of the image\n",
    "    if(emotionNr == 0):\n",
    "        emotion = 'Neutral'\n",
    "        N = N + relevant_amount\n",
    "    elif(emotionNr == 1):\n",
    "        emotion = 'Anger'\n",
    "        A = A + relevant_amount \n",
    "    # elif(emotionNr == 2):\n",
    "    # \temotion = 'Contempt'\n",
    "    # \tC = C + relevant_amount \n",
    "    elif(emotionNr == 3):\n",
    "        emotion = 'Disgust'\n",
    "        D = D + relevant_amount \n",
    "    elif(emotionNr == 4):\n",
    "        emotion = 'Fear '\n",
    "        F = F + relevant_amount \n",
    "    elif(emotionNr == 5):\n",
    "        emotion = 'Happy'\n",
    "        H = H + relevant_amount \n",
    "    elif(emotionNr == 6):\n",
    "        emotion = 'Saddness'\n",
    "        Sa = Sa + relevant_amount \n",
    "    else:\n",
    "        emotion = 'Surprise'\n",
    "        Su = Su + relevant_amount \n",
    "\n",
    "\n",
    "\n",
    "    if(emotionNr != 2):\n",
    "        # store images of the neutral expression and emotion label in the X_data and Y_data lists\n",
    "        for j in img_neutral:\n",
    "            X_data.append(j)\n",
    "            Y_data.append(2)\n",
    "            X_subID.append(subjectID)\t\n",
    "\n",
    "        # store image and emotion label in the X_data and Y_data lists\n",
    "        for j in img:\n",
    "            X_data.append(j)\n",
    "            Y_data.append(emotionNr)\n",
    "            X_subID.append(subjectID)\n",
    "\n",
    "        # print(\"X_data length \",len(X_data))\n",
    "\n",
    "        i = i+len(img) + len(img_neutral)\n",
    "\n",
    "    if (sub%20 ==0):\n",
    "        logprint(repr(sub)+\"subjects loaded\")\n",
    "        mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "        str = 'Maximum memory usage: ' + repr( mem_usage)\n",
    "        logprint(str)\n",
    "\n",
    "    if printData :\n",
    "        logging.info(\"-------------------------------\")\n",
    "\n",
    "        logging.info(str) #./cohn-kanade-images/S506/002/S506_004_00000038.png\n",
    "        logging.info(\"amount of image added \" + repr( len(img)))\n",
    "        logging.info(\"image type:   \" + repr(type(img)))\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        logging.info('image ' + repr(i) + \" \" + emotion)\n",
    "\n",
    "#show stattistics\n",
    "logging.info(\"--------- Overal stattistics ---------  \")\n",
    "logging.info(\"amount of Subjects  : \" + repr(sub))\n",
    "logging.info(\"amount of Instances : \" + repr(i))\n",
    "logging.info(\"code = 1 = Anger      \" + repr(A) + \" instances: \" + repr(np.round((float(A)/i)*100),decimals=2))\n",
    "logging.info(\"code = 2 = Neutral    \" + repr(N) + \" instances: \" + repr(np.round((float(N)/i)*100),decimals=2))\n",
    "logging.info(\"code = 3 = Disgust    \" + repr(D) + \" instances: \"+ repr(np.round((float(D)/i)*100),decimals=2))\n",
    "logging.info(\"code = 4 = Fear       \" + repr(F) + \" instances: \"+ repr(np.round((float(F)/i)*100),decimals=2))\n",
    "logging.info(\"code = 5 = Happy      \" + repr(H) + \" instances: \"+ repr(np.round((float(H)/i)*100),decimals=2))\n",
    "logging.info(\"code = 6 = Saddness   \" + repr(Sa) +\" instances: \"+ repr(np.round((float(Sa)/i)*100),decimals=2))\n",
    "logging.info(\"code = 7 = Surprise   \" + repr(Su) +\" instances: \"+ repr(np.round((float(Su)/i)*100),decimals=2))\n",
    "logging.info(\"--------- dimensions ---------  \")\n",
    "# print(repr(dimMap))\n",
    "\n",
    "logging.info(\"--------- last elements in lists ---------  \")\n",
    "logging.info(\"length X_data \" + repr(len(X_data))) \n",
    "logging.info(\"length Y_data \" + repr(len(Y_data)))\n",
    "logging.info(\"length X_subID \" + repr(len(X_subID))) \n",
    "\n",
    "\n",
    "# # cv2.imshow('image',X_data[len(X_data)-1])\n",
    "# plt.figure('last image')\n",
    "# plt.imshow(X_data[len(X_data)-1], cmap='gray')#, interpolation='nearest');\n",
    "# plt.show()\n",
    "\n",
    "print(\"length Y_data \" + repr(Y_data[len(Y_data)-1])) \n",
    "print(\"image type \" + repr(type(Y_data[len(Y_data)-1]))) \n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory usage: ' + repr( mem_usage)\n",
    "logprint(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 340, 927, 291, 183, 444, 182, 441], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bincount \n",
    "np.bincount(np.asarray(Y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(allData==True):\n",
    "#     data = load_all_annotated_CKP_data(datasetPath,printData)\n",
    "# elif(neutral == True):\n",
    "#     data = load_all_annotated_CKP_data_neutral(datasetPath,printData)\n",
    "# else:\t\t\n",
    "#     data = load_CKP_data(datasetPath,printData)\n",
    "\n",
    "# save part of the data in temp.npy files\n",
    "amount_sets = len(data)//50\n",
    "\n",
    "if not os.path.exists('./temp'):\n",
    "    os.makedirs('./temp')\n",
    "    print(\"made new directory: \" + './temp')\n",
    "\n",
    "start = 0    \n",
    "for i in range(0,amount_sets-1):\n",
    "    stre = \"./temp/temp_\" + repr(i) + \"_\" + repr(start) + \"-\" + repr(start+49) + \".npy\"\n",
    "    npy.save(stre,data[start:start+50])\n",
    "    start = start +50\n",
    "\n",
    "stre = \"temp_\" + repr(i) + \"_\" + repr(start) + \"-\" + repr(len(data)) + \".npy\"\n",
    "npy.save(stre,data[start:])\n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory usage before data = null: ' + repr( mem_usage)\n",
    "logprint(str)\n",
    "\n",
    "data = None;\n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory usage after data = null: ' + repr( mem_usage)\n",
    "logprint(str)\n",
    "\n",
    "\n",
    "\n",
    "images = data[0]\n",
    "\n",
    "# cut faces from each images and resize (downsample) to input dimension\n",
    "X_gray = []\n",
    "X_test = []\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "stre =\"total amount of images is \"+ repr( len(images) )\n",
    "logprint(stre)\n",
    "logprint(\"start cutting the faces\")\n",
    "\n",
    "list_files = glob(\"./temp/*\")\n",
    "\n",
    "for file in list_files:\n",
    "    logprint(\"load file: \" + file)\n",
    "    images = np.load(file)\n",
    "\n",
    "    for i in range(0,len(images)):\t   \n",
    "        cut_img = cutFace(images[i],224,224,faceCascade)\n",
    "        X_gray = np.append(X_gray,cut_img)\n",
    "        if(i%50 == 0):\n",
    "            stre =\" \"+ repr(i) + \" images have been processed\"\n",
    "            print(stre)\n",
    "            logging.info(stre)\n",
    "            #monitor the memory usage of the current proces for 1 second, sample each 0.2 s return list of MB values\n",
    "            mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "            str = 'Maximum memory usage: ' + repr( mem_usage)\n",
    "            logprint(str)\n",
    "\n",
    "        if printData==1 :\n",
    "#             cv2.imshow(\"example\", cut_img.reshape((224,224)))\n",
    "#             cv2.waitKey(0)\n",
    "\n",
    "X_gray = X_gray.reshape([-1,224,224,1])\n",
    "print(X_gray.shape)\n",
    "\n",
    "# reformat the emotionlabels to create a vector of 7 zeros only one of these elements is set to 1 indicating the emotion label\n",
    "labels = []\n",
    "\n",
    "logprint(\"start coverting Y_class_data to output data\")\n",
    "for lab in data[1]:\n",
    "    inst = np.zeros(7)\n",
    "    inst[lab-1] = 1\n",
    "    labels = np.append(labels,inst)\n",
    "\n",
    "print(\"size Y 2: \" + repr(labels.shape))\n",
    "\n",
    "labels = labels.reshape([-1,7]) \n",
    "\n",
    "print(\"size labels flatten: \" + repr(len(labels)))\n",
    "print(\"size labels shape: \" + repr(labels.shape))\n",
    "print(\"type labels: \" + repr(type(labels)))\n",
    "\n",
    "outputData = [X_gray,labels,data[2]]\n",
    "\n",
    "logprint(\"the end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('../data/CKP_all_neutral'):\n",
    "    os.makedirs('../data/CKP_all_neutral')\n",
    "    print(\"made new directory: \" + ' ../data/CKP_all_neutral')\n",
    "\n",
    "np.save('../data/CKP_all_neutral/X.npy',data[0])\n",
    "np.save('../data/CKP_all_neutral/Y.npy',data[1])\n",
    "np.save('../data/CKP_all_neutral/subjectIDs.npy',data[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_all_CKP_formated_data_neutral(dataPath,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
