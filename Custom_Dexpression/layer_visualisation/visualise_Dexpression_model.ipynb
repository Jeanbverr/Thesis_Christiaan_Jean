{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found path with os.path.abspath('..'):  G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\n",
      "['G:\\\\Documenten\\\\personal\\\\school\\\\MaNaMA_AI\\\\thesis\\\\implementation\\\\dexpression\\\\github_1\\\\github\\\\Thesis_Christiaan_Jean\\\\Custom_Dexpression', '', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\python36.zip', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\DLLs', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages', 'a:\\\\users\\\\christiaan\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\christiaan\\\\.ipython']\n",
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "Lpath = os.path.abspath('..')\n",
    "print(\"found path with os.path.abspath('..'): \", Lpath)\n",
    "sys.path.insert(0, Lpath)\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tflearn.activations as activations\n",
    "# Data loading and preprocessing\n",
    "from tflearn.activations import relu\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.conv import avg_pool_2d, conv_2d, max_pool_2d, global_avg_pool \n",
    "from tflearn.layers.core import dropout, flatten, fully_connected, input_data\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "\n",
    "\n",
    "\n",
    "#chris library imports\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from test_recursive_image_load_V2 import load_CKP_data\n",
    "from test_recursive_image_load_V2 import load_formated_data\n",
    "from test_recursive_image_load_V2 import split_dataset\n",
    "from test_recursive_image_load_V2 import divide_subjects\n",
    "from test_recursive_image_load_V2 import divide_data_to_subject\n",
    "from test_recursive_image_load_V2 import load_npy_files\n",
    "\n",
    "from showNumpyInfo import showInfo\n",
    "\n",
    "# from Dexpression_network import create_Dexpression_old_network\n",
    "# from Dexpression_network import create_Dexpression_network\n",
    "# # from Dexpression_network import create_Dexpression_FX2_out_layer\n",
    "\n",
    "from display_image import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] could not load from path: ./data/CKP_all \n",
      " because of: [Errno 2] No such file or directory: './data/CKP_all/X.npy' error\n",
      "[WARNING] could not load from path: ./../data/CKP_all \n",
      " because of: [Errno 2] No such file or directory: './../data/CKP_all/X.npy' error\n",
      "[SUCCEED]data found in path:  ./../../data/CKP_all\n"
     ]
    }
   ],
   "source": [
    "# global Paths to define for each specific computer\n",
    "#tf_checkpoints = where the checkpoints of tensorflow training algorithms are stored to be recovered if necessary\n",
    "tf_checkpoints = \"G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/github/Thesis_Christiaan_Jean/Custom_Dexpression/tf_checkpoints\"\n",
    "\n",
    "#load data\n",
    "# try:\n",
    "#     X_data = np.load('../data/CKP_X.npy')\n",
    "#     Y_data = np.load('../data/CKP_Y.npy')\n",
    "#     X_subID = (np.load('../data/CKP_subjectIds.npy')).astype('uint8')\n",
    "# except:\n",
    "#     X_data = np.load('G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/github/Thesis_Christiaan_Jean/data/CKP_X.npy')\n",
    "#     Y_data = np.load('G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/github/Thesis_Christiaan_Jean/data/CKP_Y.npy')\n",
    "#     X_subID = (np.load('G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/github/Thesis_Christiaan_Jean/data/CKP_subjectIds.npy')).astype('uint8')\n",
    "dire = 'CKP_all'\n",
    "\n",
    "[X_data,Y_data,X_subID] = load_npy_files(5,dire)\n",
    "\n",
    "#load the subject distribution over the different datasets\n",
    "subID = (np.load('../data_division/'+dire+'/train_subject_ID.npy')).astype('uint8')\n",
    "subID_val = (np.load('../data_division/'+dire+'/validation_subject_ID.npy')).astype('uint8')\n",
    "subID_test = (np.load('../data_division/'+dire+'/test_subject_ID.npy')).astype('uint8')\n",
    "subIDs = [subID, subID_val, subID_test]\n",
    "\n",
    "# divided_data = divide_data_to_subject([X_data,Y_data,X_subID],subIDs)\n",
    "\n",
    "# print(X.shape)\n",
    "# print(X.dtype)\n",
    "\n",
    "# def format_data(divided_data):\n",
    "#     X = (divided_data[0].reshape(-1,224,224,1)).astype('uint8')\n",
    "#     Y = (divided_data[1].reshape(-1,7)).astype('uint8')\n",
    "\n",
    "#     # create the validation set X_val and Y-val (SubID_val is not given to the network)\n",
    "#     X_val = divided_data[2].reshape(-1,224,224,1).astype('uint8')\n",
    "#     Y_val = divided_data[3].reshape(-1,7).astype('uint8')\n",
    "\n",
    "#     # create the test set X_test and Y_test (SubID_test is not given to the network)\n",
    "#     X_test = divided_data[4].reshape(-1,224,224,1).astype('uint8')\n",
    "#     Y_test = divided_data[5].reshape(-1,7).astype('uint8')  \n",
    "    \n",
    "#     return [X,Y,X_val,Y_val,X_test,Y_test]\n",
    "\n",
    "# [X,Y,X_val,Y_val,X_test,Y_test] = format_data(divided_data)\n",
    "# print(X.shape)\n",
    "# print(X.dtype)\n",
    "tf.reset_default_graph()\n",
    "tflearn.config.init_training_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "Tensor(\"FX2_out/concat:0\", shape=(?, 50, 50, 272), dtype=float32)\n",
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "    # Give a dropout if required (change to True and define the dropout percentage).\n",
    "    dropout = False\n",
    "    dropout_keep_prob = 0.5\n",
    "    \n",
    "    # Define number of output classes.\n",
    "    num_classes = 7\n",
    "\n",
    "    # Define padding scheme.\n",
    "    padding = 'VALID'\n",
    "\n",
    "    # Model Architecture\n",
    "    network = input_data(shape=[None, 224, 224, 1])\n",
    "    conv_1 = relu(conv_2d(network, 64, 7, strides=2, bias=True, padding=padding, activation=None, name='Conv2d_1'))\n",
    "    maxpool_1 = batch_normalization(max_pool_2d(conv_1, 3, strides=2, padding=padding, name='MaxPool_1'))\n",
    "    LRN_1 = local_response_normalization(maxpool_1, name='LRN_1')\n",
    "    # FeatEX-1\n",
    "    conv_2a = relu(conv_2d(maxpool_1, 96, 1, strides=1, padding=padding, name='Conv_2a_FX1'))\n",
    "    maxpool_2a = max_pool_2d(maxpool_1, 3, strides=1, padding=padding, name='MaxPool_2a_FX1')\n",
    "    conv_2b = relu(conv_2d(conv_2a, 208, 3, strides=1, padding=padding, name='Conv_2b_FX1'))\n",
    "    conv_2c = relu(conv_2d(maxpool_2a, 64, 1, strides=1, padding=padding, name='Conv_2c_FX1'))\n",
    "    FX1_out = merge([conv_2b, conv_2c], mode='concat', axis=3, name='FX1_out')\n",
    "    # FeatEX-2\n",
    "    conv_3a = relu(conv_2d(FX1_out, 96, 1, strides=1, padding=padding, name='Conv_3a_FX2'))\n",
    "    maxpool_3a = max_pool_2d(FX1_out, 3, strides=1, padding=padding, name='MaxPool_3a_FX2')\n",
    "    conv_3b = relu(conv_2d(conv_3a, 208, 3, strides=1, padding=padding, name='Conv_3b_FX2'))\n",
    "    conv_3c = relu(conv_2d(maxpool_3a, 64, 1, strides=1, padding=padding, name='Conv_3c_FX2'))\n",
    "    FX2_out = merge([conv_3b, conv_3c], mode='concat', axis=3, name='FX2_out')\n",
    "    print(FX2_out)\n",
    "    #added by Christiaan \n",
    "    GAP = global_avg_pool (FX2_out, name='GlobalAvgPool')\n",
    "    \n",
    "    net = flatten(FX2_out)\n",
    "    if dropout:\n",
    "        net = dropout(net, dropout_keep_prob)\n",
    "    loss = fully_connected(net, num_classes,activation='softmax')\n",
    "\n",
    "    # Compile the model and define the hyperparameters\n",
    "    network = tflearn.regression(loss, optimizer='Adam',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#create a custom tensorflow session to manage the used resources\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config = config)\n",
    "\n",
    "\n",
    "# Final definition of model checkpoints and other configurations\n",
    "#model = tflearn.DNN(network, checkpoint_path='/home/cc/DeXpression/DeXpression_checkpoints',\n",
    "# model = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a custom tensorflow session to manage the used resources\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tflearn.DNN(network, checkpoint_path='./tf_checkpoints',\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2)\n",
    "model = tflearn.DNN(network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\\layer_visualisation\\tf_checkpoints\\DeXpression_run_1.model\n"
     ]
    }
   ],
   "source": [
    "model.load('./tf_checkpoints/DeXpression_run_1.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model1 = tflearn.DNN(FX2_out ,session=model.session)\n",
    "model1 = tflearn.DNN(net ,session=model.session)\n",
    "model2 = tflearn.DNN(FX2_out ,session=model.session)\n",
    "model3 = tflearn.DNN(GAP ,session=model.session)\n",
    "#NOTE there is no difference between using the net layer or FX2_out \n",
    "\n",
    "\n",
    "# model3 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "# model4 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "# model5 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "\n",
    "\n",
    "# model1.load('./tf_checkpoints/DeXpression_run_1.model')\n",
    "# model3.load('./tf_checkpoints/DeXpression_run_3.model')\n",
    "# model4.load('./tf_checkpoints/DeXpression_run_4.model')\n",
    "# model5.load('./tf_checkpoints/DeXpression_run_5.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP_weights= model3.get_weights(GAP.W)\n",
    "# showInfo(GAP_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_tensor_allocations_upon_oom: true"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "# classes = create_Y_pred_classes(divided_data,model1)\n",
    "# print(classes[0])\n",
    "# print(classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data[0:1].shape\n",
    "\n",
    "display(X_data[0:1].astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_real = model.predict(X_data[0:1])  # prediction\n",
    "Y_pred = model1.predict(X_data[0:1])  # prediction\n",
    "Y_pred2 = model2.predict(X_data[0:1])  # prediction\n",
    "GAP_pred = model3.predict(X_data[0:1])  # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  UnKnown\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (1, 272)\n",
      "[[7.09497929e-02 7.92344511e-02 3.26615982e-02 1.77221105e-01\n",
      "  1.79613963e-01 3.62482481e-02 1.50022417e-01 7.13902339e-02\n",
      "  2.40649171e-02 4.26748544e-02 8.33982043e-03 4.64239195e-02\n",
      "  7.38788303e-03 1.76718652e-01 3.88964415e-02 1.89560913e-02\n",
      "  8.31491873e-03 1.28904268e-01 1.97036102e-01 9.68137458e-02\n",
      "  2.57805213e-02 1.72525898e-01 2.38229290e-01 7.01918006e-02\n",
      "  3.16089168e-02 1.09849893e-01 8.73648562e-03 4.15991433e-03\n",
      "  7.47172087e-02 1.31678343e-01 1.58947818e-02 9.96717345e-03\n",
      "  1.64457902e-04 1.42886475e-01 2.28534326e-01 1.75502561e-02\n",
      "  2.41901036e-02 1.47298396e-01 2.77230963e-02 5.58677875e-02\n",
      "  1.28561646e-01 3.24806392e-01 2.11955104e-02 8.40060562e-02\n",
      "  2.86389887e-02 9.61888283e-02 2.11796071e-02 1.99168152e-03\n",
      "  2.40402557e-02 4.71307412e-02 2.40612738e-02 8.33149999e-02\n",
      "  1.15752369e-02 0.00000000e+00 3.37164328e-02 3.05859023e-03\n",
      "  4.38170135e-03 5.66708632e-02 1.29887059e-01 3.15484256e-02\n",
      "  9.76581052e-02 5.03650680e-03 1.25385940e-01 1.35645932e-02\n",
      "  3.80595401e-02 1.14589699e-01 1.42941937e-01 4.51339670e-02\n",
      "  2.14600980e-01 8.94079059e-02 4.92122173e-02 6.85938448e-02\n",
      "  3.71567793e-02 5.48726581e-02 1.53573275e-01 1.16632218e-02\n",
      "  1.04354909e-02 1.47893801e-02 4.70456555e-02 4.81165610e-02\n",
      "  6.99554235e-02 4.86801527e-02 1.32383574e-02 9.05047357e-03\n",
      "  1.49988994e-01 1.67023856e-02 2.63271127e-02 1.51661970e-02\n",
      "  6.12888671e-02 8.94827619e-02 9.24174022e-03 6.98046433e-03\n",
      "  6.81350008e-02 6.37775660e-02 4.34143133e-02 3.95861687e-03\n",
      "  5.16666621e-02 4.02352726e-03 8.97953939e-03 1.12198353e-01\n",
      "  2.42778659e-03 5.36855077e-03 4.04547201e-03 5.78232370e-02\n",
      "  4.31976169e-02 1.25562817e-01 9.56217758e-03 3.63437422e-02\n",
      "  1.42896384e-01 5.73860575e-03 1.43312505e-02 1.48134694e-01\n",
      "  5.76721318e-03 1.21546024e-02 1.17223978e-01 4.01648842e-02\n",
      "  3.66824446e-04 4.87867482e-02 2.48338580e-01 5.10580204e-02\n",
      "  1.19401813e-02 3.72614741e-01 8.97156149e-02 1.81373600e-02\n",
      "  1.56423841e-02 3.62693608e-01 8.89056828e-03 1.68565828e-02\n",
      "  1.07045644e-05 7.87495822e-02 1.90860495e-01 2.49692593e-02\n",
      "  1.35590717e-01 2.02678628e-02 1.44712506e-02 2.29453743e-02\n",
      "  2.22235009e-01 6.15904480e-02 1.10186063e-01 1.07215866e-01\n",
      "  1.12004086e-01 1.95174739e-02 8.17698017e-02 9.93013196e-03\n",
      "  2.18403518e-01 2.49435697e-02 4.28169556e-02 1.38575146e-02\n",
      "  4.26684432e-02 1.95806604e-02 6.40663318e-03 1.01819476e-02\n",
      "  2.11484153e-02 2.60426193e-01 1.96043096e-04 1.60492048e-01\n",
      "  4.27988507e-02 5.01090623e-02 2.14393791e-02 1.97098106e-02\n",
      "  1.16716595e-02 1.22923832e-02 1.81793883e-01 3.67821753e-02\n",
      "  9.78101939e-02 3.10870945e-01 4.92282435e-02 2.91879347e-04\n",
      "  0.00000000e+00 5.16270995e-02 9.02391076e-02 2.26776744e-03\n",
      "  1.12561435e-01 3.99102345e-02 9.79332067e-03 6.21394888e-02\n",
      "  6.98558101e-03 7.78850839e-02 2.25973595e-02 3.77182141e-02\n",
      "  9.09782872e-02 1.86666939e-02 9.01782438e-02 1.75555944e-02\n",
      "  1.06050462e-01 3.62407975e-02 3.14300992e-02 3.31054605e-03\n",
      "  7.97944665e-02 2.26687014e-01 1.86339226e-02 1.52763963e-01\n",
      "  2.69013494e-02 1.07937887e-01 2.80530155e-02 7.53225535e-02\n",
      "  2.56598815e-02 1.90359410e-02 2.41572168e-02 4.84430194e-02\n",
      "  3.43259200e-02 2.11263951e-02 5.05454652e-02 1.63845599e-01\n",
      "  3.57198864e-02 3.38804582e-03 1.73578873e-01 1.36449829e-01\n",
      "  5.15685678e-02 4.56854515e-02 3.19419384e-01 4.91729355e-04\n",
      "  6.30890066e-03 4.21311846e-03 0.00000000e+00 3.26859385e-01\n",
      "  1.59392878e-02 8.54045004e-02 1.38857126e-01 1.28400385e-01\n",
      "  1.28497714e-02 1.71315148e-02 1.35593791e-03 3.94171439e-02\n",
      "  3.34553085e-02 3.98809239e-02 1.19182784e-02 4.93374377e-01\n",
      "  1.22986082e-02 7.12663261e-03 4.21519652e-02 2.62847519e-03\n",
      "  7.22144991e-02 1.59163754e-02 3.47498991e-02 1.35752738e-01\n",
      "  6.37804493e-02 1.49075210e-03 2.83021393e-04 1.93587884e-01\n",
      "  1.04806840e+00 0.00000000e+00 3.52369659e-02 1.75533473e-01\n",
      "  1.45573809e-03 4.00320470e-01 5.75120568e-01 3.39976996e-02\n",
      "  4.67710644e-02 1.22293189e-01 3.81060988e-01 7.94698477e-01\n",
      "  5.76650770e-03 8.93419921e-01 1.76695257e-01 1.82418078e-01\n",
      "  1.31193951e-01 2.18950242e-01 2.51128197e-01 3.33069786e-02\n",
      "  5.43283187e-02 1.81672648e-02 5.61746895e-01 1.82656385e-02\n",
      "  1.98925585e-01 2.49525368e-01 4.59480166e-01 9.40560072e-04\n",
      "  4.84697241e-03 1.17685064e-03 0.00000000e+00 2.22448140e-01]]\n"
     ]
    }
   ],
   "source": [
    "showInfo(GAP_pred)\n",
    "print(GAP_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  Y_pred after dropout\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (1, 680000)\n",
      "Name  Y_pred2 before dropout\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (1, 50, 50, 272)\n",
      "5.647466\n",
      "272\n",
      "Name  Y_reshape\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (224, 224, 272)\n",
      "Name  pred = reshapen Y_pred\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (1, 50, 50, 272)\n"
     ]
    }
   ],
   "source": [
    "# shows the images stored in the second to last layer\n",
    "showInfo(Y_pred,\"Y_pred after dropout\")\n",
    "showInfo(Y_pred2,\"Y_pred2 before dropout\")\n",
    "maxo = np.max(Y_pred2)\n",
    "print(maxo)\n",
    "Y_reshape = cv2.resize(Y_pred2.reshape(50,50,272),(224,224), interpolation = cv2.INTER_AREA)\n",
    "print(Y_reshape.shape[2])\n",
    "showInfo(Y_reshape,'Y_reshape')\n",
    "cv2.imshow(\"test\",Y_reshape[:,:,240])\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "pred = Y_pred.reshape(1,50,50,272)\n",
    "showInfo(pred,\"pred = reshapen Y_pred\")\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(suppress=True)\n",
    "# print(Y_pred2[0,0,0,0:50])\n",
    "# print(\"---------------------------\")\n",
    "# print(pred[0,0,0,0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0e910c155571>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"test \"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_reshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# shows all images stored in the second to last layer\n",
    "# for i in range(0,Y_reshape.shape[2]):\n",
    "                 \n",
    "# #     if(Y_reshape[:,:,i].any() >=  1):       \n",
    "# # #         print(Y_reshape[:,:,1])\n",
    "# #     print(\"max found\")\n",
    "#     str = \"test \" +  repr(i)\n",
    "#     cv2.imshow(str,(Y_reshape[:,:,i]))\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Name  weights\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (680000, 7)\n",
      "[-0.02426779  0.01906147 -0.01809155 -0.00829517  0.00523452  0.03273747\n",
      " -0.00174737]\n",
      "[ 0.02028005  0.02345897 -0.01292278  0.00358047  0.02017989  0.00263044\n",
      "  0.01224747]\n",
      "[ 0.01555516 -0.02866572 -0.00964126  0.00573142 -0.01376486 -0.02001086\n",
      "  0.01070189]\n",
      "Name  UnKnown\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float32\n",
      "shape:  (1, 680000)\n",
      "Name  UnKnown\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float64\n",
      "shape:  (7, 50, 50)\n",
      "Name  output\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  float64\n",
      "shape:  (7,)\n",
      "[   11.0337584      0.00512938 91236.31803717     0.13619357\n",
      "     0.02390368     0.005165       0.0898027 ]\n",
      "91247.61198990115\n",
      "my output,  [0.00012092 0.00000006 0.99987623 0.00000149 0.00000026 0.00000006\n",
      " 0.00000098]\n",
      "real output  [[0.00012096 0.00000006 0.99987626 0.00000149 0.00000026 0.00000006\n",
      "  0.00000098]]\n"
     ]
    }
   ],
   "source": [
    "# compare the self calculated output with the real output\n",
    "weights= model1.get_weights(loss.W)\n",
    "print(type(weights))\n",
    "showInfo(weights,'weights')\n",
    "print(weights[:20][0])\n",
    "print(weights[2500:2520][0])\n",
    "print(weights[:20][1])\n",
    "showInfo(np.exp(Y_pred))\n",
    "\n",
    "elem = np.zeros((7,50,50))\n",
    "elem_pos = np.zeros((7,50,50))\n",
    "elem_pos_1 = np.zeros((7,50,50))\n",
    "norm = np.zeros((7,50,50))\n",
    "showInfo(elem)\n",
    "\n",
    "for i in range(0,7):\n",
    "    elem[i] = np.sum(np.multiply(Y_pred,weights[:,i]).reshape(50,50,272),axis = 2)\n",
    "    elem_pos[i] = elem[i]-(np.min(elem))\n",
    "#     elem_pos[i] = np.exp(elem[i]) # try the exponent\n",
    "    norm[i] = elem_pos[i]/np.max(elem_pos) #bring weights between 0 and 1\n",
    "    \n",
    "    Y_norm = cv2.resize(norm[i],(224,224), interpolation = cv2.INTER_AREA)\n",
    "    stre= \"class \" + repr(i)\n",
    "    cv2.imshow(stre,Y_norm)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() \n",
    "#     for x in range(0,elem[i].shape[0]):\n",
    "#         for y in range(0,elem[i].shape[1]):\n",
    "#             if(elem[i][x][y] > 0 ):\n",
    "#                 elem_pos_1[i][x][y] = elem[i][x][y]\n",
    "#             else:\n",
    "#                 elem_pos_1[i][x][y] = 0 \n",
    "    \n",
    "#     norm_1 = elem_pos[i]/np.max(elem_pos)\n",
    "    \n",
    "#     Y_norm_1 = cv2.resize(norm_1,(224,224), interpolation = cv2.INTER_AREA)\n",
    "#     stre= \"class \" + repr(i)\n",
    "#     cv2.imshow(stre,Y_norm_1)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows() \n",
    "    \n",
    "#     showInfo(elem[i],'elem')\n",
    "\n",
    "\n",
    "\n",
    "output =np.exp(np.sum(np.sum(elem,axis = 1),axis = 1) )  \n",
    "# output =np.exp(np.matmul(Y_pred,weights))\n",
    "\n",
    "showInfo(output,\"output\")\n",
    "summ = np.sum(output)\n",
    "print(output)\n",
    "print(summ)\n",
    "print(\"my output, \",  output/summ)\n",
    "print(\"real output \" ,Y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,7):\n",
    "    elem_pos[i] = elem[i]-(np.min(elem))\n",
    "#     elem_pos[i] = np.exp(elem[i]) # try the exponent\n",
    "    norm[i] = elem_pos[i]/np.max(elem_pos) #bring weights between 0 and 1\n",
    "    \n",
    "    Y_norm = cv2.resize(norm[i],(224,224), interpolation = cv2.INTER_AREA)\n",
    "    stre= \"class \" + repr(i)\n",
    "    cv2.imshow(stre,Y_norm)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class_0 = (weights.reshape(50,50,272,7))[:,:,:,0]\n",
    "showInfo(weight_class_0)\n",
    "maxi = np.max(weights)\n",
    "print(maxi)\n",
    "\n",
    "vis_weights = (weights.reshape(50,50,272,7))[:,:,0,0]\n",
    "vis_224 = cv2.resize(vis_weights,(224,224), interpolation = cv2.INTER_AREA)\n",
    "showInfo(vis_weights,'weights')\n",
    "\n",
    "cv2.imshow(\"test\",vis_weights)\n",
    "cv2.waitKey(0)\n",
    "print(vis_weights[0:10,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the weight average of for 1 emotion\n",
    "for i in range(2,7):\n",
    "    multi = np.multiply((weights.reshape(50,50,272,7))[:,:,:,i],Y_pred.reshape(50,50,272))\n",
    "    showInfo(multi,multi)\n",
    "    Y_multi = cv2.resize(multi.reshape(50,50,272),(224,224), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    for i in range(0,Y_reshape.shape[2]):\n",
    "\n",
    "    #     if(Y_reshape[:,:,i].any() >=  1):       \n",
    "    # #         print(Y_reshape[:,:,1])\n",
    "#         print(\"max found\")\n",
    "        str = \"test \" +  repr(i)\n",
    "        cv2.imshow(str,(Y_multi[:,:,i]))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()    \n",
    "   \n",
    "    \n",
    "    sumi = np.sum(multi,axis=2)\n",
    "    showInfo(sumi)\n",
    "    print(\"why nut?\")\n",
    "    exp = np.exp(sumi)\n",
    "    showInfo(exp,'exp')\n",
    "    outp = exp/np.max(exp)\n",
    "    \n",
    "    \n",
    "    sumi_vis_224 = cv2.resize(outp,(224,224), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    \n",
    "    stre= \"class \" + repr(i)\n",
    "    cv2.imshow(stre,sumi_vis_224.astype('uint8'))\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
