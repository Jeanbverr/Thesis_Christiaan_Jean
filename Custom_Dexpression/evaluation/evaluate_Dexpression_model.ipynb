{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found path with os.path.abspath('..'):  G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\n",
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "Lpath = os.path.abspath('..')\n",
    "print(\"found path with os.path.abspath('..'): \", Lpath)\n",
    "sys.path.insert(0, Lpath)\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tflearn.activations as activations\n",
    "# Data loading and preprocessing\n",
    "from tflearn.activations import relu\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.conv import avg_pool_2d, conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import dropout, flatten, fully_connected, input_data\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "\n",
    "\n",
    "#chris library imports\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from test_recursive_image_load_V2 import load_CKP_data\n",
    "from test_recursive_image_load_V2 import load_formated_data\n",
    "from test_recursive_image_load_V2 import split_dataset\n",
    "from test_recursive_image_load_V2 import divide_subjects\n",
    "from test_recursive_image_load_V2 import divide_data_to_subject\n",
    "from test_recursive_image_load_V2 import opti_divide_data_to_subject\n",
    "from test_recursive_image_load_V2 import load_npy_files\n",
    "from test_recursive_image_load_V2 import load_predivided_data\n",
    "\n",
    "\n",
    "from showNumpyInfo import showInfo\n",
    "\n",
    "from Dexpression_network import create_Dexpression_old_network\n",
    "from Dexpression_network import create_original_Dexpression_network\n",
    "\n",
    "\n",
    "from confusion_matrix import plot_conf_mat\n",
    "from confusion_matrix import plot_norm_conf_mat\n",
    "from confusion_matrix import save_conf_mat\n",
    "from confusion_matrix import save_norm_conf_mat\n",
    "from confusion_matrix import extract_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global Paths to define for each specific computer\n",
    "#tf_checkpoints = where the checkpoints of tensorflow training algorithms are stored to be recovered if necessary\n",
    "\n",
    "# tf_checkpoints = \"G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/github_1/github/Thesis_Christiaan_Jean/Custom_Dexpression/tf_checkpoints\"\n",
    "\n",
    "run_directory = \"G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018\"\n",
    "\n",
    "tf_checkpoints = run_directory + \"/tf_checkpoints\"\n",
    "\n",
    "#load data\n",
    "dire = 'CKP_all_neutral'\n",
    "\n",
    "# [X_data,Y_data,X_subID] = load_npy_files(5,dire)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  X_train\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (1723, 224, 224, 1)\n",
      "Name  Y_train\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (1723, 7)\n",
      "Name  X_val\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (803, 224, 224, 1)\n",
      "Name  X_val\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (803, 224, 224, 1)\n",
      "Name  X_test\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (282, 224, 224, 1)\n",
      "Name  Y_test\n",
      "type:  <class 'numpy.ndarray'>\n",
      "Dtype:  uint8\n",
      "shape:  (282, 7)\n",
      "tot length  2808\n",
      "Maximum memory usage: [348.95703125, 348.95703125]\n"
     ]
    }
   ],
   "source": [
    "# divided_data_opti = opti_divide_data_to_subject([X_data,Y_data,X_subID],subIDs)\n",
    "\n",
    "# divided_data = divide_data_to_subject([X_data,Y_data,X_subID],subIDs)\n",
    "divided_data = load_predivided_data(dire, run_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tflearn.config.init_training_mode()\n",
    "\n",
    "network = create_original_Dexpression_network()\n",
    "\n",
    "#create a custom tensorflow session to manage the used resources\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config = config)\n",
    "\n",
    "\n",
    "# Final definition of model checkpoints and other configurations\n",
    "#model = tflearn.DNN(network, checkpoint_path='/home/cc/DeXpression/DeXpression_checkpoints',\n",
    "# model = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('./tf_checkpoints/DeXpression_run_3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(input)\n",
    "\n",
    "    if(X.shape[0] >= 50):\n",
    "        Y_train_pred_class = extract_classes(model.predict(X[:50]))\n",
    "    else:\n",
    "        Y_train_pred_class = extract_classes(model.predict(X))\n",
    "    \n",
    "    for i in range(1,floor(len(input)/50)):\n",
    "         Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[i*50:(i+1)*50])))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def create_Y_pred_classes(data,model):\n",
    "    [X,Y,X_val,Y_val,X_test,Y_test] = data\n",
    "    # predictions \n",
    "    Y_val_pred = model.predict(X_val)  # predictions\n",
    "    Y_test_pred = model.predict(X_test)  # predictions\n",
    "\n",
    "    # Y_train_pred_class = extract_classes(model.predict(X))\n",
    "\n",
    "    Y_train_pred_class = extract_classes(model.predict(X[:50]))\n",
    "    from \n",
    "    Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[50:100])))\n",
    "    Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[100:150])))\n",
    "    Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[150:200])))\n",
    "    Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[200:250])))\n",
    "    Y_train_pred_class = np.append(Y_train_pred_class,extract_classes(model.predict(X[250:])))\n",
    "\n",
    "    Y_train_class = extract_classes(Y)\n",
    "\n",
    "    # extracting classes\n",
    "    Y_val_pred_class = extract_classes(Y_val_pred)\n",
    "    Y_val_class = extract_classes(Y_val)\n",
    "\n",
    "    Y_test_pred_class = extract_classes(Y_test_pred)\n",
    "    Y_test_class = extract_classes(Y_test)\n",
    "\n",
    "    print(Y_train_class.astype('uint8'))\n",
    "    print(Y_train_pred_class.astype('uint8'))\n",
    "    \n",
    "    # making full dataset\n",
    "    Y_pred_class = Y_train_pred_class\n",
    "    Y_pred_class = np.append(Y_pred_class,Y_val_pred_class)\n",
    "    Y_pred_class = np.append(Y_pred_class,Y_test_pred_class) \n",
    "\n",
    "    Y_class = np.append(Y_train_class,Y_val_class)\n",
    "    Y_class = np.append(Y_class,Y_test_class)\n",
    "    \n",
    "    return [Y_train_class, Y_train_pred_class,\n",
    "            Y_val_class, Y_val_pred_class, \n",
    "            Y_test_class, Y_test_pred_class, \n",
    "            Y_class, Y_pred_class   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Y_train_class, Y_train_pred_class, Y_val_class, Y_val_pred_class, Y_test_class, Y_test_pred_class, Y_class, Y_pred_class   ] = create_Y_pred_classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate global accuracy\n",
    "#sum of all correct (top-1) classification divide by the sum off all predictions\n",
    "# IN:\n",
    "# Y_class: Np.ndarray (Nx1) correct class labels  \n",
    "# Y_pred_class: Np.ndarray (Nx1) predicted class labels \n",
    "# OUT:\n",
    "# accuracy value (float64)\n",
    "def global_acc(Y_class,Y_pred_class,verbose = 0):\n",
    "    Y_class_corr = np.asarray([]) \n",
    "    for i in range(0,Y_pred_class.astype('uint8').shape[0]):\n",
    "        if(verbose >=2):\n",
    "            print('Y_class[ ',i,'] ' ,Y_class[i])\n",
    "            print('Y_pred_class[ ',i,'] ',Y_pred_class[i])\n",
    "            print(Y_pred_class[i] == Y_class[i])\n",
    "        if(Y_pred_class[i] == Y_class[i]):\n",
    "            Y_class_corr = np.append(Y_class_corr,1)\n",
    "        else:\n",
    "            Y_class_corr = np.append(Y_class_corr,0)\n",
    "                        \n",
    "    Y_pred_class_count = np.bincount(Y_class_corr.astype('uint8'),minlength=2)\n",
    "    acc = Y_pred_class_count.astype('float64')[1]/(Y_pred_class_count.astype('float64').sum())\n",
    "    \n",
    "    if(verbose >=1):\n",
    "        print(Y_class_corr)\n",
    "        print(Y_pred_class_count)\n",
    "        print(acc)\n",
    "        \n",
    "    return acc\n",
    "\n",
    "#TEST\n",
    "\n",
    "# Y_t_class = np.arange(10)\n",
    "# print(Y_t_class)\n",
    "# Y_t_predict = np.asarray([0,1,2,4,4,5,7,7,8,9]) \n",
    "# print(Y_t_predict)\n",
    "# print(global_acc(Y_t_class,Y_t_predict,0))\n",
    "def display_all_acc(classes,modelID = 'NaN'):\n",
    "    print(\"model_\",modelID)\n",
    "    [   Y_train_class, Y_train_pred_class,\n",
    "                        Y_val_class, Y_val_pred_class, \n",
    "                        Y_test_class, Y_test_pred_class, \n",
    "                        Y_class, Y_pred_class   ] = classes\n",
    "    \n",
    "    \n",
    "    glob_acc = global_acc(Y_class,Y_pred_class)\n",
    "    train_acc = global_acc(Y_train_class,Y_train_pred_class)\n",
    "    val_acc = global_acc(Y_val_class,Y_val_pred_class)\n",
    "    test_acc = global_acc(Y_test_class,Y_test_pred_class)\n",
    "\n",
    "    print(\"train accuracy     : \", train_acc)\n",
    "    print(\"validation accuracy: \", val_acc)\n",
    "    print(\"test accuracy      : \", test_acc)\n",
    "    print(\"global accuracy    : \", glob_acc)\n",
    "    \n",
    "# display_all_acc([Y_train_class, Y_train_pred_class, Y_val_class, Y_val_pred_class, Y_test_class, Y_test_pred_class, Y_class, Y_pred_class   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bin_count(Y_class,title = 'no title',size=(20,14)):\n",
    "    x = ['Anger','Contempt','Disgust','Fear','Happy','Saddness','Surprise']\n",
    "    y = np.bincount(Y_class.astype('uint8'),minlength=7)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.bar(x,y)\n",
    "    plt.title(title)\n",
    "    for i, v in enumerate(y):\n",
    "        plt.text(i - size[0]/160, v  + size[1]/40  , str(v), color='black', fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_conf_mat(classes,modelID = 'NaN'):\n",
    "    [   Y_train_class, Y_train_pred_class,\n",
    "                        Y_val_class, Y_val_pred_class, \n",
    "                        Y_test_class, Y_test_pred_class, \n",
    "                        Y_class, Y_pred_class   ] = classes\n",
    "    \n",
    "    \n",
    "    \n",
    "    conf_mat_train = tf.confusion_matrix(Y_train_class,Y_train_pred_class,num_classes=7,dtype=tf.int32)#,# name=None,# weights=None)\n",
    "    conf_mat_val = tf.confusion_matrix(Y_val_class,Y_val_pred_class,num_classes=7,dtype=tf.int32)#,# name=None,# weights=None)\n",
    "    conf_mat_test = tf.confusion_matrix(Y_test_class,Y_test_pred_class,num_classes=7,dtype=tf.int32)#,# name=None,# weights=None)\n",
    "    conf_mat = tf.confusion_matrix(Y_class,Y_pred_class,num_classes=7,dtype=tf.int32)#,# name=None,# weights=None)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    plot_conf_mat(sess.run(conf_mat_train),('training_model_',modelID),(10,7))\n",
    "    plot_conf_mat(sess.run(conf_mat_val),('validation_model_',modelID),(10,7))\n",
    "    plot_conf_mat(sess.run(conf_mat_test),('test_model_',modelID),(10,7))\n",
    "    plot_conf_mat(sess.run(conf_mat),('full_model_',modelID),(10,7))\n",
    "    \n",
    "    plot_norm_conf_mat(sess.run(conf_mat_train),('training_normalised_model_',modelID),(10,7))\n",
    "    plot_bin_count(Y_train_class,('training set class distribution model_',modelID),(10,7))\n",
    "    \n",
    "    plot_norm_conf_mat(sess.run(conf_mat_val),('validation_normalised_model_',modelID),(10,7))\n",
    "    plot_bin_count(Y_val_class,('validation set class distribution',modelID),(10,7))\n",
    "        \n",
    "    plot_norm_conf_mat(sess.run(conf_mat_test),('test_normalised_model_',modelID),(10,7))\n",
    "    plot_bin_count(Y_test_class,('test set class distribution model_',modelID),(10,7))\n",
    "        \n",
    "    plot_norm_conf_mat(sess.run(conf_mat),('full_normalised_model_',modelID),(10,7))\n",
    "    plot_bin_count(Y_class,('full set class distribution model_',modelID),(10,7))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model_analysis(data,model,modelID = \"NaN\"):\n",
    "    classes = create_Y_pred_classes(data,model)\n",
    "    display_all_acc(classes,modelID)\n",
    "    all_conf_mat(classes,modelID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a custom tensorflow session to manage the used resources\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "\n",
    "model1 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "                    max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "# model3 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "# model4 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "# model5 = tflearn.DNN(network, checkpoint_path=tf_checkpoints,\n",
    "#                     max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir=\"./tflearn_logs/\")\n",
    "\n",
    "\n",
    "\n",
    "# model1.load('./tf_checkpoints/DeXpression_run_1.model')\n",
    "# model3.load('./tf_checkpoints/DeXpression_run_3.model')\n",
    "# model4.load('./tf_checkpoints/DeXpression_run_4.model')\n",
    "# model5.load('./tf_checkpoints/DeXpression_run_5.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_tensor_allocations_upon_oom: true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "# classes = create_Y_pred_classes(divided_data,model1)\n",
    "# print(classes[0])\n",
    "# print(classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\n",
      "['G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\checkpoint', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_1.model.data-00000-of-00001', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_1.model.index', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_1.model.meta', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_2.model.data-00000-of-00001', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_2.model.index', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_2.model.meta', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_3.model.data-00000-of-00001', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_3.model.index', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_3.model.meta', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_4.model.data-00000-of-00001', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_4.model.index', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_4.model.meta', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_5.model.data-00000-of-00001', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_5.model.index', 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/condor_runs/12_29-04-2018/tf_checkpoints\\\\DeXpression_run_5.model.meta']\n",
      "G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\condor_runs\\12_29-04-2018\\tf_checkpoints\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "string = run_directory + '/tf_checkpoints'\n",
    "print(string)\n",
    "print(glob(string+'/*'))\n",
    "\n",
    "os.chdir(string)\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\condor_runs\\12_29-04-2018\\tf_checkpoints\\DeXpression_run_1.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\condor_runs\\12_29-04-2018\\tf_checkpoints\\DeXpression_run_1.model\n"
     ]
    }
   ],
   "source": [
    "model1.load( 'DeXpression_run_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[803,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2d_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_InputData/X_0_0/_143, Conv2d_1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: FullyConnected/BiasAdd/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_152_FullyConnected/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2d_1/Conv2D', defined at:\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b24d522037a7>\", line 4, in <module>\n    network = create_original_Dexpression_network()\n  File \"G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\\Dexpression_network.py\", line 143, in create_original_Dexpression_network\n    conv_1 = relu(conv_2d(network, 64, 7, strides=2, bias=True, padding=padding, activation=None, name='Conv2d_1'))\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[803,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2d_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_InputData/X_0_0/_143, Conv2d_1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: FullyConnected/BiasAdd/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_152_FullyConnected/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[803,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2d_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_InputData/X_0_0/_143, Conv2d_1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: FullyConnected/BiasAdd/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_152_FullyConnected/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-26419328750f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_model_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdivided_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-d826fe5f4bfa>\u001b[0m in \u001b[0;36mfull_model_analysis\u001b[1;34m(data, model, modelID)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfull_model_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodelID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_Y_pred_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdisplay_all_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodelID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mall_conf_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodelID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6f09483c8c7d>\u001b[0m in \u001b[0;36mcreate_Y_pred_classes\u001b[1;34m(data, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mY_val_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mY_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m    256\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\helpers\\evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, feed_dict)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[803,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2d_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_InputData/X_0_0/_143, Conv2d_1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: FullyConnected/BiasAdd/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_152_FullyConnected/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2d_1/Conv2D', defined at:\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b24d522037a7>\", line 4, in <module>\n    network = create_original_Dexpression_network()\n  File \"G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\implementation\\dexpression\\github_1\\github\\Thesis_Christiaan_Jean\\Custom_Dexpression\\Dexpression_network.py\", line 143, in create_original_Dexpression_network\n    conv_1 = relu(conv_2d(network, 64, 7, strides=2, bias=True, padding=padding, activation=None, name='Conv2d_1'))\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 717, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"a:\\users\\christiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[803,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2d_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_InputData/X_0_0/_143, Conv2d_1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: FullyConnected/BiasAdd/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_152_FullyConnected/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "full_model_analysis(divided_data,model1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load(tf_checkpoints + '/DeXpression_run_3.model')\n",
    "full_model_analysis(divided_data,model1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.load(tf_checkpoints + '/DeXpression_run_4.model')\n",
    "full_model_analysis(divided_data,model1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load(tf_checkpoints + '/DeXpression_run_5.model')\n",
    "full_model_analysis(divided_data,model1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model_analysis(divided_data,model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "368px",
    "left": "1644.32px",
    "right": "20px",
    "top": "121.997px",
    "width": "467px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
