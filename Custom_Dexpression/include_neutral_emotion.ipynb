{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0,'C:/Users/JeanBV/Documents/TFLearn_2/age-gender-estimation')\n",
    "\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cutFace algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#give grayscale image and 2D height and width of output and a facecascade\n",
    "def cutFace(img,width,height,casc, database):\n",
    "\n",
    "    try:\n",
    "        if(database == 'MUG'):\n",
    "            minSizeX = 100\n",
    "            minSizeY = 100\n",
    "        else:\n",
    "            minSizeX = 100\n",
    "            minSizeY = 100\n",
    "        # Detect faces in the image\n",
    "        faces = casc.detectMultiScale(\n",
    "            img,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(minSizeX, minSizeY),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        if(len(faces)!=0):\n",
    "            for (x, y, w, h) in faces:\n",
    "                if w > h :\n",
    "                    he = w//2\n",
    "                    wi = w//2\n",
    "                else :\n",
    "                    he = h//2\n",
    "                    wi = h//2\n",
    "\n",
    "                x_m = (x+w//2)\n",
    "                y_m = (y+h//2)\n",
    "                \n",
    "                cut_image = img[y_m-he:y_m+he,x_m-wi:x_m+wi]\n",
    "                cut_image = cv2.resize(cut_image,(width,height), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        return cut_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative cutFace algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# def cutFace(img,width,height, cascade, database):\n",
    "\n",
    "#     try:\n",
    "#         minisize = (img.shape[1],img.shape[0])\n",
    "#         miniframe = cv2.resize(img, minisize)\n",
    "\n",
    "#         faces = cascade.detectMultiScale(miniframe)\n",
    "#         if(database == 'MMI'):\n",
    "#             if(len(faces == 0)):\n",
    "#                 img = np.rot90(img, k = 3)\n",
    "#         for f in faces:\n",
    "#             x, y, w, h = [ v for v in f ]\n",
    "#             cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255))\n",
    "\n",
    "#             sub_face = img[y:y+h, x:x+w]\n",
    "#             sub_face = cv2.resize(sub_face,(width,height), interpolation = cv2.INTER_AREA)\n",
    "#         if(len(faces)>=2):\n",
    "#             cv2.imshow(\"frame\", sub_face)\n",
    "#             cv2.waitKey()\n",
    "#         return sub_face\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree\n",
    "from lxml import etree\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get datapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for jean\n",
    "data_path_CASPEAL = \"C:/Users/JeanBV/Documents/databases/CAS_PEAL/CAS-PEAL-R1\"\n",
    "data_path_JAFFE = \"C:/Users/JeanBV/Documents/databases/JAFFE_frames\"\n",
    "# data_path_MUG = \"C:/Users/JeanBV/Documents/databases/MUG/\"\n",
    "# data_path_MMI = \"C:/Users/JeanBV/Documents/databases/MMI\"\n",
    "data_path_CKP = \"C:/Users/JeanBV/Documents/databases/CK+\"\n",
    "\n",
    "#  for christiaan\n",
    "data_path_MMI = \"G:/Documenten/personal/school/MaNaMA_AI/thesis/databases/wikipedia_list/MMI/download_22-11-2017\"\n",
    "data_path_MUG = \"G:\\Documenten\\personal\\school\\MaNaMA_AI\\thesis\\databases\\wikipedia_list\\MUG\\subjects3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get frames from videos with starting to ending frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frames_from_vid(path):\n",
    "#     cap = cv2.VideoCapture(path) #video_name is the video being called\n",
    "#     cap.set(1, frame_no); # Where frame_no is the frame you want\n",
    "#     ret, frame = cap.read() # Read the frame\n",
    "#     cv2.imwrite(\"frames/\"+path.split(\"\\\\\")[9].split(\".\")[0]+\".jpg\", frame)     # save frame as JPEG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_vid(path,subject, start, end):\n",
    "#     frame_dir= \"Frame\"\n",
    "    subject_dir = subject\n",
    "    list_of_frames = []\n",
    "    \n",
    "    #Not used right now\n",
    "    \n",
    "#     if not os.path.exists(frame_dir):\n",
    "#         os.makedirs(frame_dir)\n",
    "#     current_directory = os.path.abspath(frame_dir)\n",
    "#     subject_dir = os.path.join(current_directory, subject_dir)\n",
    "#     if not os.path.exists(subject_dir):\n",
    "#         os.makedirs(subject_dir) \n",
    "        \n",
    "    cap = cv2.VideoCapture(path) #video_name is the video being called\n",
    "    \n",
    "    cap.set(1,start); # Where frame_no is the frame you want\n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    count = start\n",
    "    while count <= end:\n",
    "        list_of_frames.append(frame)\n",
    "#       cv2.imwrite(\"Frame/\"+subject+\"/\"+subject+\"%d.jpg\" % count, frame)     # save frame as JPEG file      \n",
    "        ret,frame = cap.read()\n",
    "        count += 1\n",
    "    return list_of_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\"C:/qsdqsd/qsdqsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def input_MMI_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, printData = 0):\n",
    "    #subject counter   \n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "    i = 0\n",
    "    dimMap = {}\n",
    "    list_emotions=[]\n",
    "    #intialize database path\n",
    "    data_path = data_path_MMI\n",
    "    #change directory to where the dB is situated\n",
    "    os.chdir(data_path)\n",
    "    label_expression = glob('./Sessions/*/*')\n",
    "    amount_of_emotion = 0\n",
    "    length_neutral_frames = 0\n",
    "    length_all_frames = 0\n",
    "    x_neutral = []\n",
    "    x_emotion = []\n",
    "    # print(os.getcwd())\n",
    "    k = 0\n",
    "    \n",
    "    for file in label_expression:\n",
    "\n",
    "        if(file.endswith('.avi')):\n",
    "            xml_file = \".\"+file.split(\".\",-1)[1]+'.xml'\n",
    "            myroot = xml.etree.ElementTree.parse(xml_file).getroot()\n",
    "            for line in myroot.findall('Metatag'):\n",
    "                if(line.attrib['Name'] == 'Emotion'):\n",
    "                    #Extracting emotion\n",
    "                    emotion_label = int(line.attrib['Value'])\n",
    "\n",
    "            #Getting video\n",
    "            video_path = os.path.abspath(file)\n",
    "\n",
    "            #Get unique subject\n",
    "            subjectID = video_path.split(\"\\\\\")[-1].split(\".\")[0].split(\"-\")[0]\n",
    "            if subjectID != lastSub:\n",
    "                sub = sub + 1\n",
    "            lastSub = subjectID\n",
    "            \n",
    "            IDNumber = int(subjectID[1:])\n",
    "\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            get_middle = int(video_length/2)\n",
    "\n",
    "            lower_bound = get_middle - round(video_length/8)\n",
    "            upper_bound = get_middle + round(video_length/8)\n",
    "\n",
    "            #Get frames for emotions\n",
    "            frames = get_frames_from_vid(video_path, subjectID, lower_bound, upper_bound)\n",
    "            k = k+1\n",
    "            if(k%50 ==0):\n",
    "                mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "                str = 'Maximum memory after loading ' + repr(i) + \"images is \" + repr( mem_usage)\n",
    "                print(str)\n",
    "            \n",
    "            #Get neutral frames\n",
    "            #First 5%\n",
    "            frames_neutral_first_5 = get_frames_from_vid(video_path, subjectID, 0, int(video_length*0.015))\n",
    "            #Last 5%\n",
    "            frames_neutral_last_5 = get_frames_from_vid(video_path, subjectID, int(video_length*0.985), video_length)\n",
    "\n",
    "            neutral_frames = frames_neutral_first_5 + frames_neutral_last_5\n",
    "            \n",
    "            X_data_before = len(X_data)\n",
    "            #Neutral\n",
    "            for frame in neutral_frames:\n",
    "                if(frame is not None):\n",
    "                    x = int(frame.shape[1])\n",
    "                    if(subjectID == 'S001') or (subjectID == 'S002') or (subjectID == 'S017') :\n",
    "                        sliced_image = frame[:, int(x/2):, :]\n",
    "                    elif(subjectID == 'S003') or (subjectID == 'S005') or (subjectID == 'S006') or (subjectID == 'S015')or (subjectID == 'S016'):\n",
    "                        sliced_image = frame[:, 0:int(x/2), :]\n",
    "                    elif(subjectID == 'S021'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        sliced_image = frame\n",
    "                    sliced_image = cv2.cvtColor(sliced_image, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    if(IDNumber > 21):\n",
    "                        sliced_image = np.rot90(sliced_image, k = 3)\n",
    "                        \n",
    "                    X_data.append(sliced_image)\n",
    "                    \n",
    "            X_data_now_neutr = len(X_data)\n",
    "                                     \n",
    "            #Neutral\n",
    "            #Get amount of neutral emotions to be added\n",
    "            amount_of_neutral = X_data_now_neutr - X_data_before\n",
    "            data_shape = np.zeros(amount_of_neutral).shape\n",
    "            #Get Y_data\n",
    "            #Neutral is characterized as a zero.\n",
    "            Y_data_neutral = np.full(amount_of_neutral, 2) \n",
    "            #Get X_subID data\n",
    "            X_subID_neutral = np.full(Y_data_neutral.shape, subjectID)\n",
    "            i = i + amount_of_neutral\n",
    "\n",
    "            #Store emotion label and subjectID in the corresponding lists\n",
    "            Y_data.extend(Y_data_neutral)\n",
    "            X_subID.extend(X_subID_neutral)\n",
    "\n",
    "            N = N + amount_of_neutral\n",
    "                \n",
    "            length_x_neutral = len(X_data)\n",
    "            #Emotions\n",
    "            \n",
    "            #These frames all have the same emotional label. They come from the same video. So it is safe to generalize all the emotions.\n",
    "            for frame in frames:\n",
    "                if(frame is not None) and (emotion_label >=0) and (emotion_label <=7):\n",
    "                    x = int(frame.shape[1])\n",
    "                    if(subjectID == 'S001') or (subjectID == 'S002') or (subjectID == 'S017') :\n",
    "                        sliced_image = frame[:, int(x/2):, :]\n",
    "                    elif(subjectID == 'S003') or (subjectID == 'S005') or (subjectID == 'S006') or (subjectID == 'S015')or (subjectID == 'S016'):\n",
    "                        sliced_image = frame[:, 0:int(x/2), :]\n",
    "                    elif(subjectID == 'S021'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        sliced_image = frame\n",
    "                        \n",
    "                    #Change to gray image\n",
    "                    sliced_image = cv2.cvtColor(sliced_image, cv2.COLOR_BGR2GRAY)\n",
    "                    if(IDNumber > 21):\n",
    "                        sliced_image = np.rot90(sliced_image, k = 3)\n",
    "                    X_data.append(sliced_image)\n",
    "                    \n",
    "            X_data_now_emotion = len(X_data)\n",
    "            \n",
    "            #Get amount of same emotion to be added\n",
    "            amount_of_emotion = X_data_now_emotion - X_data_now_neutr\n",
    "\n",
    "            if(emotion_label >=0) and (emotion_label <=7):\n",
    "                #Mapping emotions to emotion values\n",
    "                if(emotion_label == 1):\n",
    "                    emotion_label_add = 1\n",
    "                    emotion = 'Anger'\n",
    "                    A = A + amount_of_emotion\n",
    "                elif(emotion_label == 2):\n",
    "                    emotion_label_add = 3\n",
    "                    emotion = 'Disgust'\n",
    "                    D = D + amount_of_emotion\n",
    "                elif(emotion_label == 3):\n",
    "                    emotion_label_add = 4\n",
    "                    emotion = 'Fear '\n",
    "                    F = F + amount_of_emotion\n",
    "                elif(emotion_label == 4):\n",
    "                    emotion_label_add = 5\n",
    "                    emotion = 'Happy'\n",
    "                    H = H + amount_of_emotion\n",
    "                elif(emotion_label == 5):\n",
    "                    emotion_label_add = 6\n",
    "                    emotion = 'Saddness'\n",
    "                    Sa = Sa + amount_of_emotion\n",
    "                elif(emotion_label == 6):\n",
    "                    emotion_label_add = 7\n",
    "                    emotion = 'Surprise'\n",
    "                    Su = Su + amount_of_emotion\n",
    "\n",
    "                #Get np array size / shape\n",
    "                data_shape = np.zeros(amount_of_emotion).shape\n",
    "                #Get Y_data\n",
    "                Y_data_emotion = np.full(data_shape, emotion_label_add)\n",
    "                #Get X_subID data\n",
    "                X_subID_emotion = np.full(data_shape, subjectID)\n",
    "                i = i + amount_of_emotion\n",
    "                Y_data.extend(Y_data_emotion)\n",
    "                X_subID.extend(X_subID_emotion)\n",
    "\n",
    "    return X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def input_MMI_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, printData = 0):\n",
    "#     #subject counter   \n",
    "#     sub = 0\n",
    "#     lastSub = 0\n",
    "#     subjectID = 0\n",
    "#     i = 0\n",
    "#     dimMap = {}\n",
    "#     list_emotions=[]\n",
    "#     #intialize database path\n",
    "#     data_path = data_path_MMI\n",
    "#     emotionNr = 0\n",
    "#     #change directory to where the dB is situated\n",
    "#     os.chdir(data_path)\n",
    "#     label_expression = glob('./Sessions/*/*')\n",
    "\n",
    "#     # print(os.getcwd())\n",
    "\n",
    "#     for file in label_expression[0:50]:\n",
    "\n",
    "#         if(file.endswith('.avi')):\n",
    "#             xml_file = \".\"+file.split(\".\",-1)[1]+'.xml'\n",
    "#             myroot = xml.etree.ElementTree.parse(xml_file).getroot()\n",
    "#             for line in myroot.findall('Metatag'):\n",
    "#                 if(line.attrib['Name'] == 'Emotion'):\n",
    "#                     #Extracting emotion\n",
    "#                     emotionNr = line.attrib['Value']\n",
    "\n",
    "#             #Getting video\n",
    "#             video_path = os.path.abspath(file)\n",
    "\n",
    "#             #Get unique subject\n",
    "#             subjectID = video_path.split(\"\\\\\")[-1].split(\".\")[0].split(\"-\")[0]\n",
    "#             if subjectID != lastSub:\n",
    "#                 sub = sub + 1\n",
    "#             lastSub = subjectID\n",
    "\n",
    "#             cap = cv2.VideoCapture(video_path)\n",
    "#             video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#             get_middle = int(video_length/2)\n",
    "\n",
    "#             lower_bound = get_middle - round(video_length/8)\n",
    "#             upper_bound = get_middle + round(video_length/8)\n",
    "\n",
    "#             #Get frames for emotions\n",
    "#             frames = get_frames_from_vid(video_path, subjectID, lower_bound, upper_bound)\n",
    "            \n",
    "# #             #Get frames for neutral emotions. We expect the first 5% and last 5% of the videos to be of a neutral emotion.\n",
    "# #             #First 5%\n",
    "# #             frames_neutral_first_5 = get_frames_from_vid(video_path, subjectID, 0, int(videolength*0.05))\n",
    "# #             #Last 5%\n",
    "# #             frames_neutral_last_5 = get_frames_from_vid(video_path, subjectID, int(videolength*0.95), videolength)\n",
    "\n",
    "# #             neutral_frames = frames_neutral_first_5 + frames_neutral_last_5\n",
    "# #             X_data_neutral = frames_neutral_first_5 + frames_neutral_last_5\n",
    "# #             Y_data_neutral = np.zeros(len(X_data_neutral))\n",
    "# #             X_subID_neutral = np.full(Y_data_neutral.shape, subjectID)\n",
    "\n",
    "# #             for frame in neutral_frames:\n",
    "# #                 if(frame is not None):\n",
    "# #                     x = int(frame.shape[1])\n",
    "# #                     if(subjectID == 'S001') or (subjectID == 'S002'):\n",
    "# #                         sliced_image = frame[:, int(x/2):, :]\n",
    "# #                     elif(subjectID == 'S003') or (subjectID == 'S005') or (subjectID == 'S006') or (subjectID == 'S0015'):\n",
    "# #                         sliced_image = frame[:, 0:int(x/2), :]\n",
    "# #                     elif(subjectID == 'S021'):\n",
    "# #                         continue\n",
    "# #                     else:\n",
    "# #                         sliced_image = frame\n",
    "                \n",
    "\n",
    "#                     x = int(frame.shape[1])\n",
    "#                     if(subjectID == 'S001') or (subjectID == 'S002'):\n",
    "#                         sliced_image = frame[:, int(x/2):, :]\n",
    "#                     elif(subjectID == 'S003') or (subjectID == 'S005') or (subjectID == 'S006') or (subjectID == 'S0015'):\n",
    "#                         sliced_image = frame[:, 0:int(x/2), :]\n",
    "#                     elif(subjectID == 'S021'):\n",
    "#                         continue\n",
    "#                     else:\n",
    "#                         sliced_image = frame\n",
    "\n",
    "#                     sliced_image = cv2.cvtColor(sliced_image, cv2.COLOR_BGR2GRAY)\n",
    "#                     emotionNr = int(emotionNr)\n",
    "#                     original_emotion = emotionNr\n",
    "\n",
    "#                     if(int(emotionNr) >=0) and (int(emotionNr) <=7):\n",
    "                        \n",
    "#                         #Mapping emotions to emotion values\n",
    "#                         if(int(emotionNr) == 1):\n",
    "#                             emotionNr = 1\n",
    "#                             emotion = 'Anger'\n",
    "#                             A = A + 1\n",
    "#                         elif(emotionNr == 2):\n",
    "#                             emotionNr = 3\n",
    "#                             emotion = 'Disgust'\n",
    "#                             D = D + 1\n",
    "#                         elif(emotionNr == 3):\n",
    "#                             emotionNr = 4\n",
    "#                             emotion = 'Fear '\n",
    "#                             F = F + 1\n",
    "#                         elif(emotionNr == 4):\n",
    "#                             emotionNr = 5\n",
    "#                             emotion = 'Happy'\n",
    "#                             H = H + 1\n",
    "#                         elif(emotionNr == 5):\n",
    "#                             emotionNr = 6\n",
    "#                             emotion = 'Saddness'\n",
    "#                             Sa = Sa + 1\n",
    "#                         elif(emotionNr == 6):\n",
    "#                             emotionNr = 7\n",
    "#                             emotion = 'Surprise'\n",
    "#                             Su = Su + 1\n",
    "\n",
    "#                         #Store image and emotion label in the X_data and Y_data lists\n",
    "#                         X_data.append(neutr_X)\n",
    "#                         X_data.append(sliced_image)\n",
    "#                         Y_data.append(emotionNr)\n",
    "#                         X_subID.append(subjectID)\n",
    "#                         i = i+1\n",
    "\n",
    "#                         #load in original emotion again\n",
    "#                         emotionNr = original_emotion\n",
    "\n",
    "#     return X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> CKP database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_CKP_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, C, printData = 0):\n",
    "    #stores the current working directory path to restore at the end and goes to the given database path\n",
    "    curr_path = os.getcwd()\n",
    "    #subject counter   \n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "    i = 0\n",
    "    dimMap = {}\n",
    "    list_emotions=[]\n",
    "    #intialize database path\n",
    "    data_path = data_path_CKP\n",
    "    emotionNr = 0\n",
    "    #change directory to where the dB is situated\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    label_list = glob('./Emotion/*/*/*.txt')\n",
    "\n",
    "    X_data = [] # list of input data = climax images of emotions\n",
    "    Y_data = [] # list of output data = emotion expressed in image\n",
    "\n",
    "    X_subID = [] # list with subject Id of each X_data element \n",
    "\n",
    "    i = 0 #count of total amount of instances\n",
    "    \n",
    "    #subject counter\n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "\n",
    "    dimMap = {}\n",
    "\n",
    "\n",
    "    #iterate through the list of label files, open corresponding images\n",
    "    for fn in label_list[0:500]:\n",
    "        str = './cohn-kanade-images'+ fn[9:-12] + '.png'\n",
    "        image = cv2.imread(str)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # emotion label\n",
    "        file = open(fn,'r')\n",
    "        fileTxt = file.read()\n",
    "\n",
    "        emotionNr = int(fileTxt[3:4])\n",
    "        #print(\"emotion:\", emotionNr)\n",
    "        file.close()\n",
    "\n",
    "        #determine the subject\n",
    "        subjectID = fn[11:14]\n",
    "        if subjectID != lastSub :\n",
    "            sub = sub + 1\n",
    "        lastSub = subjectID \n",
    "\n",
    "        #determine the emotion of the image\n",
    "        if(emotionNr == 0):\n",
    "            emotion = 'Neutral'\n",
    "            N = N + 1\n",
    "        elif(emotionNr == 1):\n",
    "            emotion = 'Anger'\n",
    "            A = A + 1\n",
    "        elif(emotionNr == 2):\n",
    "            emotion = 'Contempt'\n",
    "            C = C + 1\n",
    "        elif(emotionNr == 3):\n",
    "            emotion = 'Disgust'\n",
    "            D = D + 1\n",
    "        elif(emotionNr == 4):\n",
    "            emotion = 'Fear '\n",
    "            F = F + 1\n",
    "        elif(emotionNr == 5):\n",
    "            emotion = 'Happy'\n",
    "            H = H + 1\n",
    "        elif(emotionNr == 6):\n",
    "            emotion = 'Saddness'\n",
    "            Sa = Sa + 1\n",
    "        else:\n",
    "            emotion = 'Surprise'\n",
    "            Su = Su + 1\n",
    "\n",
    "        #Store image and emotion label in the X_data and Y_data lists\n",
    "        X_data.append(img)\n",
    "        Y_data.append(emotionNr)\n",
    "        X_subID.append(subjectID)\n",
    "        i = i+1\n",
    "\n",
    "    return X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> MUG database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #intialize database path\n",
    "# data_path = data_path_MUG\n",
    "\n",
    "# #change directory to where the dB is situated\n",
    "# os.chdir(data_path)\n",
    "\n",
    "# #The different emotions are stored in different folders accross the directory\n",
    "# label_expression = glob('./*/*/*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for image in label_expression:\n",
    "#     emotion_label = image.split(\"\\\\\")[2]\n",
    "#     save_path = os.path.abspath(image)\n",
    "#     #Get list of images\n",
    "#     image_list = os.listdir(image)\n",
    "#     for image in image_list:\n",
    "#         if(image.endswith(\".jpg\")) or (image.endswith(\".avi\")):\n",
    "#             ok = True\n",
    "#         else:\n",
    "#             ok = False\n",
    "#     if(ok):\n",
    "#         print(emotion_label)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def input_MUG_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, printData = 0):\n",
    "    #subject counter   \n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "    i = 0\n",
    "    dimMap = {}\n",
    "    \n",
    "    #intialize database path\n",
    "    data_path = data_path_MUG\n",
    "\n",
    "    #change directory to where the dB is situated\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    #The different emotions are stored in different folders accross the directory\n",
    "    label_expression = glob('./*/*/*/')\n",
    "    label_session_expression = glob('./*/session*/*/*/')\n",
    "    \n",
    "\n",
    "#     for image in label_session_expression[0:5]:\n",
    "        \n",
    "#         #Get amount of images per emotion\n",
    "#         amount_of_images = len(os.listdir(image))\n",
    "        \n",
    "#         #Get emotion label\n",
    "        \n",
    "#         emotion_label = image.split(\"\\\\\")[3]\n",
    "#         if(emotion_label != 'mixed'):\n",
    "            \n",
    "#             #Get middle image\n",
    "#             middle_image = round(amount_of_images/2)    \n",
    "            \n",
    "#             #Create bounds\n",
    "#             lower_bound = middle_image - round(amount_of_images/8)\n",
    "#             upper_bound = middle_image + round(amount_of_images/8)\n",
    "            \n",
    "#             #Get list of images\n",
    "#             image_list =(os.listdir(image))\n",
    "            \n",
    "#             #Bound the list of images\n",
    "#             image_list_bound = (image_list[lower_bound:upper_bound])\n",
    "#             for k in range(len(image_list_bound)):\n",
    "#                 img_path = (os.path.abspath(image)+\"\\\\\"+image_list_bound[k])\n",
    "#                 image_rd = cv2.imread(img_path)\n",
    "#                 img = cv2.cvtColor(image_rd, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#                  #Get emotion labels\n",
    "#                 if(emotion_label == 'neutral'):\n",
    "#                     emotion_label_add = 2\n",
    "#                     emotion = 'Neutral'\n",
    "#                     N = N + 1\n",
    "#                 elif(emotion_label == 'anger'):\n",
    "#                     emotion_label_add = 1\n",
    "#                     emotion = 'Anger'\n",
    "#                     A = A + 1\n",
    "#                 elif(emotion_label == 'disgust'):\n",
    "#                     emotion_label_add = 3\n",
    "#                     emotion = 'Disgust'\n",
    "#                     D = D + 1\n",
    "#                 elif(emotion_label == 'fear'):\n",
    "#                     emotion_label_add = 4\n",
    "#                     emotion = 'Fear '\n",
    "#                     F = F + 1\n",
    "#                 elif(emotion_label == 'happiness'):\n",
    "#                     emotion_label_add = 5\n",
    "#                     emotion = 'Happy'\n",
    "#                     H = H + 1\n",
    "#                 elif(emotion_label == 'sadness'):\n",
    "#                     emotion_label_add = 6\n",
    "#                     emotion = 'Saddness'\n",
    "#                     Sa = Sa + 1\n",
    "#                 elif(emotion_label == 'surprise'):\n",
    "#                     emotion_label_add = 7\n",
    "#                     emotion = 'Surprise'\n",
    "#                     Su = Su + 1\n",
    "\n",
    "#                 subjectID = img_path.split(\"\\\\\")[6]\n",
    "#                 if subjectID != lastSub :\n",
    "#                     sub = sub + 1\n",
    "#                 lastSub = subjectID \n",
    "\n",
    "#                 # store image and emotion label in the X_data and Y_data lists\n",
    "#                 X_data.append(img)               \n",
    "#                 Y_data.append(emotion_label_add)\n",
    "#                 X_subID.append(subjectID)\n",
    "#                 i = i+1\n",
    "\n",
    "    for image in label_expression:\n",
    "        save_path = os.path.abspath(image)\n",
    "        amount_of_images = len(os.listdir(image))\n",
    "        emotion_label = image.split(\"\\\\\")[2]\n",
    "        #Get list of images\n",
    "        image_list = os.listdir(image)\n",
    "        for image in image_list:\n",
    "            if(image.endswith(\".jpg\")) or (image.endswith(\".avi\")):\n",
    "                ok = True\n",
    "            else:\n",
    "                ok = False\n",
    "        if(ok):\n",
    "            #Exclude mixed emotion\n",
    "            if(emotion_label != 'mixed'):\n",
    "                #Get the middle_image\n",
    "                middle_image = round(amount_of_images/2)\n",
    "\n",
    "                #Create bounds\n",
    "                lower_bound = middle_image - round(amount_of_images/8)\n",
    "                upper_bound = middle_image + round(amount_of_images/8)\n",
    "                #Bound the list of images\n",
    "                image_list_bound = (image_list[lower_bound:upper_bound])\n",
    "                for k in range(len(image_list_bound)):\n",
    "                    img_path = (save_path+\"\\\\\"+image_list_bound[k])\n",
    "                    if(img_path.endswith(\"jpg\")):\n",
    "                        print(\"image path:\", img_path)\n",
    "                        image_rd = cv2.imread(img_path)\n",
    "                        img = cv2.cvtColor(image_rd, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    original_emotion = emotion_label\n",
    "                    if(emotion_label == 'neutral'):\n",
    "                        emotion_label_add = 2\n",
    "                        emotion = 'Neutral'\n",
    "                        N = N + 1\n",
    "                    elif(emotion_label == 'anger'):\n",
    "                        emotion_label_add = 1\n",
    "                        emotion = 'Anger'\n",
    "                        A = A + 1\n",
    "                    elif(emotion_label == 'disgust'):\n",
    "                        emotion_label_add = 3\n",
    "                        emotion = 'Disgust'\n",
    "                        D = D + 1\n",
    "                    elif(emotion_label == 'fear'):\n",
    "                        emotion_label_add = 4\n",
    "                        emotion = 'Fear'\n",
    "                        F = F + 1\n",
    "                    elif(emotion_label == 'happiness'):\n",
    "                        emotion_label_add = 5\n",
    "                        emotion = 'Happy'\n",
    "                        H = H + 1\n",
    "                    elif(emotion_label == 'sadness'):\n",
    "                        emotion_label_add = 6\n",
    "                        emotion = 'Saddness'\n",
    "                        Sa = Sa + 1\n",
    "                    elif(emotion_label == 'surprise'):\n",
    "                        emotion_label_add = 7\n",
    "                        emotion = 'Surprise'\n",
    "                        Su = Su + 1\n",
    "\n",
    "                    #Get subject\n",
    "                    subjectID = img_path.split(\"\\\\\")[6]\n",
    "                    if subjectID != lastSub :\n",
    "                        sub = sub + 1\n",
    "                    lastSub = subjectID \n",
    "\n",
    "                    # store image and emotion label in the X_data and Y_data lists\n",
    "                    X_data.append(img)\n",
    "                    Y_data.append(emotion_label_add)\n",
    "                    X_subID.append(subjectID)\n",
    "                    i = i+1\n",
    "                \n",
    "    return X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> JAFFE database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def input_JAFFE_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, printData = 0):\n",
    "\n",
    "    #subject counter\n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "    i = 0\n",
    "    dimMap = {}\n",
    "    #intialize database path\n",
    "    data_path = data_path_JAFFE\n",
    "\n",
    "    #change directory to where the dB is situated\n",
    "    os.chdir(data_path)\n",
    "    print(os.path.abspath(data_path))\n",
    "\n",
    "    #get the emotion expressions\n",
    "    label_expression = glob('./*.tiff')\n",
    "    for fn in label_expression:\n",
    "\n",
    "        #get emotion\n",
    "        emotion_label = fn.split(\".\")[2][0:2]\n",
    "\n",
    "        #load image\n",
    "        image = cv2.imread(fn)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if(emotion_label == 'NE'):\n",
    "            emotion_label_add = 2\n",
    "            emotion = 'Neutral'\n",
    "            N = N + 1\n",
    "        elif(emotion_label == 'AN'):\n",
    "            emotion_label_add = 1\n",
    "            emotion = 'Anger'\n",
    "            A = A + 1\n",
    "        elif(emotion_label == 'DI'):\n",
    "            emotion_label_add = 3\n",
    "            emotion = 'Disgust'\n",
    "            D = D + 1\n",
    "        elif(emotion_label == 'FE'):\n",
    "            emotion_label_add =4\n",
    "            emotion = 'Fear '\n",
    "            F = F + 1\n",
    "        elif(emotion_label == 'HA'):\n",
    "            emotion_label_add =5\n",
    "            emotion = 'Happy'\n",
    "            H = H + 1\n",
    "        elif(emotion_label == 'SA'):\n",
    "            emotion_label_add =6\n",
    "            emotion = 'Saddness'\n",
    "            Sa = Sa + 1\n",
    "        elif(emotion_label == 'SU'):\n",
    "            emotion_label_add =7\n",
    "            emotion = 'Surprise'\n",
    "            Su = Su + 1\n",
    "\n",
    "        #get subjectID\n",
    "        subjectID = fn.split(\".\")[1][1:]\n",
    "        if subjectID != lastSub:\n",
    "            sub = sub + 1\n",
    "        lastSub = subjectID\n",
    "\n",
    "        #store image and emotion label in the X_data and Y_data lists\n",
    "        X_data.append(img)\n",
    "        Y_data.append(emotion_label_add)\n",
    "        X_subID.append(subjectID)\n",
    "        i = i+1\n",
    "    return X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> CASPEAL database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_CASPEAL_database(X_data, Y_data, X_subID, N, A, H, Su, printData = 0):\n",
    "\n",
    "    #subject counter\n",
    "    sub = 0\n",
    "    lastSub = 0\n",
    "    subjectID = 0\n",
    "    i = 0\n",
    "    dimMap = {}\n",
    "    \n",
    "    #intialize database path\n",
    "    data_path = data_path_CASPEAL\n",
    "\n",
    "    #change directory to where the dB is situated\n",
    "    os.chdir(data_path)\n",
    "\n",
    "    #get the emotion expressions\n",
    "    label_expression = glob('./FRONTAL/Expression/*.tif')\n",
    "    label_neutral = glob('./FRONTAL/Normal/*.tif')\n",
    "\n",
    "    label_total = label_expression + label_neutral\n",
    "    #remove unused emotions. This way we don't loop through unneeded emotions.\n",
    "    for remove_image in label_total:\n",
    "        if(remove_image.split(\"+\")[2].split(\"_\")[1][1] == \"C\") or (remove_image.split(\"+\")[2].split(\"_\")[1][1] == \"O\"):\n",
    "            label_total.remove(remove_image)\n",
    "            \n",
    "    for fn in label_total:\n",
    "        #Get emotion number\n",
    "        emotion_label = fn.split(\"+\")[2].split(\"_\")[1][1]\n",
    "        \n",
    "        #Load the imae\n",
    "        image = cv2.imread(fn)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Get emotion labels\n",
    "        if(emotion_label == 'N'):\n",
    "            emotion_label_add = 2\n",
    "            emotion = 'Neutral'\n",
    "            N = N + 1\n",
    "        elif(emotion_label == 'F'):\n",
    "            emotion_label_add = 1\n",
    "            emotion = 'Anger'\n",
    "            A = A + 1\n",
    "        elif(emotion_label == 'L'):\n",
    "            emotion_label_add = 5\n",
    "            emotion = 'Happy'\n",
    "            H = H + 1\n",
    "        elif(emotion_label == 'S'):\n",
    "            emotion_label_add = 7\n",
    "            emotion = 'Surprise'\n",
    "            Su = Su + 1\n",
    "\n",
    "        #Get subject\n",
    "        subjectID = fn.split(\"\\\\\")[1].split(\"_\")[1]\n",
    "        if subjectID != lastSub :\n",
    "            sub = sub + 1\n",
    "        lastSub = subjectID \n",
    "\n",
    "        # store image and emotion label in the X_data and Y_data lists\n",
    "        X_data.append(img)\n",
    "        Y_data.append(emotion_label_add)\n",
    "        X_subID.append(subjectID)\n",
    "        i = i+1\n",
    "\n",
    "    return X_data, Y_data, X_subID, sub, i, N, A, H, Su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load data algo </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy as sc\n",
    "# import matplotlib.pyplot as plt\n",
    "from glob import glob \n",
    "import re\n",
    "import os\n",
    "\n",
    "import tflearn\n",
    "\n",
    "def load_data(database): \n",
    "        \n",
    "    #stores the current working directory path to restore at the end.\n",
    "    curr_path = os.getcwd()\n",
    "    \n",
    "    #Initialization\n",
    "    X_data = [] # list of input data = climax images of emotions\n",
    "    Y_data = [] # list of output data = emotion expressed in image\n",
    "    X_subID = [] # list with subject Id of each X_data element \n",
    "\n",
    "    i = 0 #count of total amount of instances\n",
    "\n",
    "    #Count per emotion\n",
    "    N = 0 # Neutral\n",
    "    A = 0 # Anger\n",
    "    C = 0 # Contempt\n",
    "    D = 0 # Disgust\n",
    "    F = 0 # Feard\n",
    "    H = 0 # Happy\n",
    "    Sa = 0# Saddness\n",
    "    Su = 0# Surprise\n",
    "\n",
    "    #Get X_data, Y_data, and other details of each of the databases\n",
    "    #Since the data is differently distributed accross the different databases, seperate functions are created \n",
    "    if(database == \"CASPEAL\"):\n",
    "        X_data, Y_data, X_subID, sub, i, N, A, H, Su = input_CASPEAL_database(X_data, Y_data, X_subID, N, A, H, Su)\n",
    "\n",
    "    if(database == \"MUG\"):\n",
    "        X_data, Y_data, X_subID, sub, i, N, A, D, H,F, Sa, Su = input_MUG_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F)\n",
    "\n",
    "    if(database == \"JAFFE\"):\n",
    "        X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su = input_JAFFE_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F)\n",
    "\n",
    "    if(database == \"MMI\"):\n",
    "        from time import time\n",
    "        t0 = time()\n",
    "        X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su = input_MMI_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F)\n",
    "        t1 = time()\n",
    "        print('function vers1 takes %f' %(t1-t0))\n",
    "\n",
    "    if(database == \"CKP\"):\n",
    "        X_data, Y_data, X_subID, sub, i, N, A, D, H, F, Sa, Su, C = input_CKP_database(X_data, Y_data, X_subID, N, A, D, H, Sa, Su, F, C)\n",
    "        \n",
    "    #show stattistics\n",
    "    print(\"--------- Overal stattistics ---------  \")\n",
    "    print(\"amount of Subjects  : %d\" % sub)\n",
    "    print(\"amount of Instances : %d\" % i)\n",
    "    print(\"code = 0 = Neutral    %d instances: %.2f\"  % (N,((float(N)/i)*100)))\n",
    "    print(\"code = 1 = Anger      %d instances: %.2f\"  % (A,((float(A)/i)*100)))\n",
    "    print(\"code = 2 = Contempt   %d instances: %.2f\"  % (C,((float(C)/i)*100)))\n",
    "    print(\"code = 3 = Disgust    %d instances: %.2f\"  % (D,((float(D)/i)*100)))\n",
    "    print(\"code = 4 = Fear       %d instances: %.2f\"  % (F,((float(F)/i)*100)))\n",
    "    print(\"code = 5 = Happy      %d instances: %.2f\"  % (H,((float(H)/i)*100)))\n",
    "    print(\"code = 6 = Saddness   %d instances: %.2f\"  % (Sa,((float(Sa)/i)*100)))\n",
    "    print(\"code = 7 = Surprise   %d instances: %.2f\"  % (Su,((float(Su)/i)*100)))\n",
    "    print(\"--------- dimensions ---------  \")\n",
    "\n",
    "    print(\"--------- last elements in lists ---------  \")\n",
    "    print(\"length X_data\" + repr(len(X_data))) \n",
    "    print(\"length Y_data\" + repr(len(Y_data))) \n",
    "\n",
    "#     plt.figure('last image')\n",
    "#     plt.imshow(X_data[len(X_data)-1], cmap='gray')#, interpolation='nearest');\n",
    "#     plt.show()\n",
    "\n",
    "    print(\"length Y_data \" + repr(Y_data[len(Y_data)-1])) \n",
    "    print(\"image type \" + repr(type(Y_data[len(Y_data)-1]))) \n",
    "\n",
    "    #Original path restored\n",
    "    os.chdir(curr_path)\n",
    "\n",
    "    return [X_data,Y_data,X_subID]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def load_formated_data(data,database, printData = 0, cascPath = \"C:/Users/JeanBV/Documents/Thesis_Christiaan_Jean/Custom_Dexpression/haarcascade.xml\"):\n",
    "\n",
    "#     data = load_data(database)\n",
    "#     print(\"test\")\n",
    "    #data[0] = X images\n",
    "    #data[2] = Y emotion labels\n",
    "    #data[3] = subject Ids\n",
    "#     print(\"data:\", data)\n",
    "    images = data[0][:50]\n",
    "    emotion_labels = data[1][:50]\n",
    "    subjects = data[2][:50]\n",
    "    emotion_labels_new = []\n",
    "    subjectID = []\n",
    "    # cut faces from each images and resize (downsample) to input dimension\n",
    "    X_gray = []\n",
    "    X_test = []\n",
    "\n",
    "    # Create the haar cascade\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    \n",
    "    for i in range(0,len(images)):\n",
    "        cut_img = cutFace(images[i],224,224,faceCascade, database)\n",
    "        #Be sure that cut_img is initialized\n",
    "        if(cut_img is not None):\n",
    "            X_gray = np.append(X_gray,cut_img)\n",
    "            emotion_labels_new.append(emotion_labels[i])\n",
    "            subjectID.append(subjects[i])\n",
    "        \n",
    "        if(i%50 ==0):\n",
    "        \tmem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "        \tstr = 'Maximum memory after cutting ' + repr(i) + \" is \" + repr( mem_usage)\n",
    "        \tprint(str)\n",
    "            \n",
    "    #Resize to 224x224 image for input of neural networkCKE\n",
    "    X_gray = X_gray.reshape([-1,224,224,1])\n",
    "\n",
    "    # reformprint(at the emotionlabels to create a vector of 7 zeros only one of these elements is set to 1 indicating the emotion label\n",
    "    labels = []\n",
    "\n",
    "    for lab in emotion_labels_new:\n",
    "        inst = np.zeros(7)\n",
    "        inst[lab-1] = 1\n",
    "        #print (inst)\n",
    "        labels = np.append(labels,inst)\n",
    "\n",
    "    print(\"size Y 2: \" + repr(labels.shape))\n",
    "\n",
    "    labels = labels.reshape([-1,7])\n",
    "\n",
    "    print(\"size labels flatten: \" + repr(len(labels)))\n",
    "    print(\"size labels shape: \" + repr(labels.shape))\n",
    "    print(\"type labels: \" + repr(type(labels)))\n",
    "\n",
    "    outputData = [X_gray,labels,subjectID]\n",
    "\n",
    "    print(\"ouputData\", outputData)\n",
    "    return outputData\n",
    "\n",
    "\n",
    "    #data = load_formated_database(dataPath,0)\n",
    "\n",
    "def create_formated_data(data,database, printData = 0, cascPath = \"C:/Users/JeanBV/Documents/Thesis_Christiaan_Jean/Custom_Dexpression/haarcascade.xml\" , databasePath = 'C:/Users/JeanBV/Documents/Thesis_Christiaan_Jean/Custom_Dexpression/'):\n",
    "   \n",
    "#     data = load_formated_data(database, printData, cascPath)\n",
    "    \n",
    "    os.chdir(databasePath)\n",
    "    print(\"making dB\")\n",
    "  \n",
    "    #Creating directories to save the npy files of the database\n",
    "    database = database\n",
    "    npy_folder = \"output_npy\"\n",
    "    if not os.path.exists(npy_folder):\n",
    "        os.makedirs(npy_folder)\n",
    "\n",
    "    current_directory = os.path.abspath(npy_folder)\n",
    "    subject_dir = os.path.join(current_directory, database) #The rule to get the folder INSIDE the folder\n",
    "    if not os.path.exists(subject_dir):\n",
    "        os.makedirs(subject_dir)\n",
    "   \n",
    "    X_data = data[0].astype('uint8')\n",
    "    np.save(subject_dir+\"\\\\\"+database+'_X.npy',X_data)\n",
    "    np.save(subject_dir+\"\\\\\"+database+'_Y.npy',data[1])\n",
    "    np.save(subject_dir+\"\\\\\"+database+'_subjectIDs.npy',data[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create_formated_data('MUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Christiaan Vanbergen\n",
    "\n",
    "database ='MMI'\n",
    "cascPath = 'G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/MMI_data_creation/Thesis_Christiaan_Jean/Custom_Dexpression/haarcascade.xml'\n",
    "databasePath ='G:/Documenten/personal/school/MaNaMA_AI/thesis/implementation/dexpression/MMI_data_creation/Thesis_Christiaan_Jean/Custom_Dexpression/MMI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "data = load_data(database)\n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory after loading data ' + repr( mem_usage)\n",
    "print(str)\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "data = load_formated_data(data,database, 0, cascPath)\n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory after formatting data ' + repr( mem_usage)\n",
    "print(str)\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "create_formated_data(data,database,0,cascPath,databasePath)\n",
    "\n",
    "mem_usage = memory_usage(-1, interval=.2, timeout=1)\n",
    "str = 'Maximum memory creating formated data ' + repr( mem_usage)\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/JeanBV/Documents/Thesis_Christiaan_Jean/Custom_Dexpression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUG =  [np.load('./output_npy/MUG/MUG_X.npy'), np.load('./output_npy/MUG/MUG_Y.npy'), np.load('./output_npy/MUG/MUG_subjectIDs.npy')]\n",
    "# MMI = [np.load('./output_npy/MMI/MMI_X.npy'), np.load('./output_npy/MMI/MMI_Y.npy'), np.load('./output_npy/MMI/MMI_subjectIDs.npy')]\n",
    "# CASPEAL = [np.load('./output_npy/CASPEAL/CASPEAL_X.npy'), np.load('./output_npy/CASPEAL/CASPEAL_Y.npy'), np.load('./output_npy/CASPEAL/CASPEAL_subjectIDs.npy')]\n",
    "# JAFFE = [np.load('./output_npy/JAFFE/JAFFE_X.npy'), np.load('./output_npy/JAFFE/JAFFE_Y.npy'), np.load('./output_npy/JAFFE/JAFFE_subjectIDs.npy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating emotional labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry = np.array([1.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "neutral = np.array([0.0,1.0,0.0,0.0,0.0,0.0,0.0])\n",
    "disgust = np.array([0.0,0.0,1.0,0.0,0.0,0.0,0.0])\n",
    "fear = np.array([0.0,0.0,0.0,1.0,0.0,0.0,0.0])\n",
    "happy = np.array([0.0,0.0,0.0,0.0,1.0,0.0,0.0])\n",
    "sad = np.array([0.0,0.0,0.0,0.0,0.0,1.0,0.0])\n",
    "surprise = np.array([0.0,0.0,0.0,0.0,0.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emotion_list(database):\n",
    "    emotion_list = []\n",
    "    for i in range(len(database[1])):\n",
    "        if(np.array_equal(angry,database[1][i])):\n",
    "            emotion = 'angry'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(neutral,database[1][i])):\n",
    "            emotion = 'neutral'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(disgust,database[1][i])):\n",
    "            emotion = 'disgust'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(fear,database[1][i])):\n",
    "            emotion = 'fear'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(happy,database[1][i])):\n",
    "            emotion = 'happy'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(sad,database[1][i])):\n",
    "            emotion = 'sad'\n",
    "            emotion_list.append(emotion)\n",
    "        elif(np.array_equal(surprise,database[1][i])):\n",
    "            emotion = 'surprise'\n",
    "            emotion_list.append(emotion)\n",
    "    return emotion_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying emotion vs face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUG_emotion = create_emotion_list(MUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing emotion vs face imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_database_pics(database, emotions):\n",
    "    for i in range(len(database[0])):\n",
    "        cv2.imshow(\"Emotion: \"+ emotions[i], database[0][i].astype('uint8'))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_database_pics(MUG, MUG_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing neutral faces and corresponding subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neutral_faces(database, emotions):\n",
    "    neutral_faces = []\n",
    "    subject_ID = []\n",
    "    for i in range(len(database[0])):\n",
    "        if(emotions[i] == 'neutral'):\n",
    "            neutral_faces.append(database[0][i])\n",
    "            subject_ID.append(database[2][i])\n",
    "    return neutral_faces, subject_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index 0: pics, index 1: subject IDs\n",
    "neutral_MUG = get_neutral_faces(MUG, MUG_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking neutral faces and subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_neutral_faces(neutral_database):\n",
    "    for i in range(len(neutral_database[0])):\n",
    "        cv2.imshow(neutral_database[1][i], neutral_database[0][i].astype('uint8'))\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neutral_faces(neutral_MUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gender and age classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "from contextlib import contextmanager\n",
    "from wide_resnet import WideResNet\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "pretrained_model = \"https://github.com/yu4u/age-gender-estimation/releases/download/v0.5/weights.18-4.06.hdf5\"\n",
    "modhash = '89f56a39a78454e96379348bddd78c0d'\n",
    "\n",
    "#Loading in CAS_PEAL dB first\n",
    "ages_arr=[]\n",
    "# CAS_PEAL_img = CAS_PEAL_filepaths_subj()\n",
    "# ages_arr = CAS_PEAL_img\n",
    "\n",
    "img_arr = []\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=1, thickness=2):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "\n",
    "def load_images(depth = 16, k = 8, weight_file = None):\n",
    "    if not weight_file:\n",
    "        weight_file = get_file(\"weights.18-4.06.hdf5\", pretrained_model, cache_subdir=\"pretrained_models\",\n",
    "                               file_hash=modhash, cache_dir=os.path.dirname(os.path.abspath('C:/Users/JeanBV/Documents/TFLearn_2/age-gender-estimation/pretrained_models')))\n",
    "    \n",
    "    # for face detection\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # load model and weights\n",
    "    img_size = 64\n",
    "    model = WideResNet(img_size, depth=depth, k=k)()\n",
    "    model.load_weights(weight_file)\n",
    "    \n",
    "    MMI_pics = neutral_MUG\n",
    "\n",
    "#     for pic in MUG_pics[0:20]:\n",
    "    for i in range(len(MMI_pics[0])):\n",
    "        classified_MMI_pics = main(\"MMI\",MMI_pics[0][i], MMI_pics[1][i], detector, model, img_size)\n",
    "#     for pic in DISFA_pics:\n",
    "#         array_DISFA_pics = main(\"DISFA\", pic, detector, model, img_size)\n",
    "#     for pic in MMI_pics:\n",
    "#         array_MNIST_pics = main(\"MMI\", pic, detector, model, img_size)\n",
    "#     for pic in CKE_pics:\n",
    "#         array_CKE_pics = main(\"CKE\", pic, detector, model, img_size)\n",
    "#     for pic in JAFFE_pics:\n",
    "#         array_JAFFE_pics = main(\"JAFFE\", pic, detector, model, img_size)\n",
    "   \n",
    "    return classified_MMI_pics\n",
    "def main(src, img, subjectID, detector, model, img_size):\n",
    "    \n",
    "    #Get BGR in order for the detector to work.\n",
    "    input_img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "    cut_image = cv2.resize(input_img, (64, 64), interpolation = cv2.INTER_AREA)\n",
    "    cut_image = np.expand_dims(cut_image, axis=0)\n",
    "#     detected = detector(input_img, 1)\n",
    "#     img_h, img_w, _ = np.shape(input_img)\n",
    "#     faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "    \n",
    "#     print(faces.shape)\n",
    "    # predict ages and genders of the detected faces\n",
    "    results = model.predict(cut_image)\n",
    "    predicted_genders = results[0]\n",
    "    ages = np.arange(0, 101).reshape(101, 1)\n",
    "    predicted_ages = results[1].dot(ages).flatten()\n",
    "        \n",
    "#     cv2.imshow(\"image\", cut_image)\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "    print(\"genders: \", predicted_genders)\n",
    "    print(\"ages: \", predicted_ages[0])\n",
    "    # draw results\n",
    "    if predicted_genders[0][0] > 0.5:\n",
    "        gender = \"F\"\n",
    "    else:\n",
    "        gender = \"M\"\n",
    "    \n",
    "    ages_arr.append([src, subjectID, int(predicted_ages[0]), gender])\n",
    "    return ages_arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "MUG_data = load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create dataframe\n",
    "classification_df = pd.DataFrame(MUG_data, columns = ['dB', 'ID', 'Age', 'Gender'])\n",
    "classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Get median age and gender ratio\n",
    "\n",
    "#Expects dataframe from the database-data\n",
    "def get_median_age_and_gender(dataframe):\n",
    "    age_and_gender = []\n",
    "    for unique_ID in unique_IDs:\n",
    "        database = dataframe[dataframe['ID'] == unique_ID]['dB'].iloc[0]\n",
    "        #Using median to get rid of uitschieters\n",
    "        median_age = dataframe[dataframe['ID'] == unique_ID]['Age'].median()\n",
    "        if(median_age >=35):\n",
    "            age = 'O'\n",
    "        else:\n",
    "            age = 'Y'\n",
    "        female_count = dataframe[dataframe['ID'] == unique_ID][dataframe['Gender']=='F'].count()[0]\n",
    "        male_count = dataframe[dataframe['ID'] == unique_ID][dataframe['Gender']=='M'].count()[0]\n",
    "        if(male_count == 0.0):\n",
    "            male_count = 1.0\n",
    "        ratio = female_count/male_count\n",
    "        if(ratio <=1.0):\n",
    "            gender = \"M\"\n",
    "        else:\n",
    "            gender = \"F\"\n",
    "        age_and_gender.append([database, unique_ID, age, gender])\n",
    "\n",
    "    return age_and_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get array of unique IDs\n",
    "unique_IDs = list(classification_df['ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data = get_median_age_and_gender(classification_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newly created database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df = pd.DataFrame(data = classified_data, columns = ['dB', 'ID', 'Age', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_ethnicity(df):\n",
    "    for i in range(len(df)):\n",
    "        if(df['dB'].loc[i]=='CASPEAL') or (df['dB'].loc[i]=='JAFFE'):\n",
    "            df['Ethnicity']='A'\n",
    "        else:\n",
    "            df['Ethnicity']='C'\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classified_df = include_ethnicity(classified_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(df):\n",
    "    F = df[df['Gender']=='F']\n",
    "    M = df[df['Gender']=='M']\n",
    "\n",
    "    YF = F[F['Age']=='Y']\n",
    "    YM = M[M['Age']=='Y']\n",
    "\n",
    "    OF =  F[F['Age']=='O']\n",
    "    OM =  M[M['Age']=='O']\n",
    "\n",
    "    YFC = YF[YF['Ethnicity']=='C']\n",
    "    YMC = YM[YM['Ethnicity']=='C']\n",
    "    OFC = OF[OF['Ethnicity']=='C']\n",
    "    OMC = OM[OM['Ethnicity']=='C']\n",
    "\n",
    "    YFA = YF[YF['Ethnicity']=='A']\n",
    "    YMA = YM[YM['Ethnicity']=='A']\n",
    "    OFA = OF[OF['Ethnicity']=='A']\n",
    "    OMA = OM[OM['Ethnicity']=='A']\n",
    "    \n",
    "    return [YFC,YMC,OFC,OMC,YFA,YMA,OFA,OMA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[YFC,YMC,OFC,OMC,YFA,YMA,OFA,OMA] = create_models(classified_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = copy.deepcopy(classified_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ('C:\\qsdqsd\\qsdqsd\\qsdqsd')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.insert(len(test_df), 'lol', 6)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df.insert(1, 'test', 6)\n",
    "classified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in classified_df.iloc[YFC.index[1]]:\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(YFC.index)):\n",
    "    classified_df.iloc[YFC.index[i]]['label'][1]\n",
    "    \n",
    "classified_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classified_df.equals(YFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [[1,2],[3,2]]\n",
    "\n",
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [[1,2],[3,2]]\n",
    "\n",
    "np.save('C:/Users/JeanBV/Documents/databases/lol.npy', a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth_test =  np.load('C:/Users/JeanBV/Documents/databases/lol.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_IDs_from_df():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(YFC), print(YMC), print(OMC), print(YFA), print(YMA), print(OFA), print(OMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = classified_df[classified_df['Gender']=='F']['Age']=='Y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort images in folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories():\n",
    "    subjects_dir='Subjects'\n",
    "    male_dir='Male_Subjects'\n",
    "    female_dir='Female_Subjects'\n",
    "    old_male_dir='Old_Male_Subjects'\n",
    "    old_female_dir='Old_Female_Subjects'\n",
    "    young_male_dir='Young_Male_Subjects'\n",
    "    young_female_dir='Young_Female_Subjects'\n",
    "    if not os.path.exists(subjects_dir):\n",
    "        os.makedirs(subjects_dir)\n",
    "        current_directory = os.path.abspath(subjects_dir)\n",
    "        male_dir = os.path.join(current_directory, male_dir)\n",
    "        female_dir = os.path.join(current_directory, female_dir)\n",
    "        if not os.path.exists(male_dir):\n",
    "            os.makedirs(male_dir)\n",
    "            current_directory = os.path.abspath(male_dir)\n",
    "            old_male_path = os.path.join(current_directory, old_male_dir)\n",
    "            young_male_path = os.path.join(current_directory, young_male_dir)\n",
    "            if not os.path.exists(old_male_path):\n",
    "                os.makedirs(old_male_path)\n",
    "            if not os.path.exists(young_male_path):\n",
    "                os.makedirs(young_male_path)\n",
    "        if not os.path.exists(female_dir):\n",
    "            os.makedirs(female_dir)\n",
    "            current_directory = os.path.abspath(female_dir)\n",
    "            old_female_path = os.path.join(current_directory, old_female_dir)\n",
    "            young_female_path = os.path.join(current_directory, young_female_dir)\n",
    "            if not os.path.exists(old_female_path):\n",
    "                os.makedirs(old_female_path)\n",
    "            if not os.path.exists(young_female_path):\n",
    "                os.makedirs(young_female_path)\n",
    "    return subjects_dir, male_dir, female_dir, old_male_dir, old_female_dir, young_male_dir, young_female_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_classification_dirs():\n",
    "subjects_dir, male_dir, female_dir, old_male_dir, old_female_dir, young_male_dir, young_female_dir = make_directories()\n",
    "\n",
    "path_female = classification_df[(classification_df['Gender']=='F')]\n",
    "path_male = classification_df[(classification_df['Gender']=='M')]\n",
    "female_young = path_female[path_female['Age']=='Y']['Path']\n",
    "female_old = path_female[path_female['Age']=='O']['Path']\n",
    "male_young = path_male[path_male['Age']=='Y']['Path']\n",
    "male_old = path_male[path_male['Age']=='O']['Path']\n",
    "try:\n",
    "    for path in female_old:\n",
    "        shutil.copy2(path, subjects_dir+'\\\\'+female_dir +'\\\\'+old_female_dir ) # complete target filename given\n",
    "    for path in male_old:\n",
    "        shutil.copy2(path,subjects_dir+'\\\\'+ male_dir +'\\\\'+old_male_dir)\n",
    "    for path in female_young:\n",
    "        shutil.copy2(path, subjects_dir+'\\\\'+female_dir +'\\\\'+young_female_dir)\n",
    "    for path in male_young:\n",
    "        shutil.copy2(path,subjects_dir+'\\\\'+ male_dir +'\\\\'+young_male_dir)\n",
    "except Exception as e:\n",
    "    print(\"Folder already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
